{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü•• Coconut Mite Detection - High Accuracy Model Training\n",
    "\n",
    "**Optimized for Google Colab with GPU**\n",
    "\n",
    "## Features:\n",
    "- Multiple model architectures comparison\n",
    "- Advanced data augmentation\n",
    "- Learning rate scheduling\n",
    "- K-Fold Cross Validation\n",
    "- Ensemble predictions\n",
    "- TensorFlow Lite export for mobile\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (for Colab)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GPU STATUS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"‚úÖ GPU Available: {gpus}\")\n",
    "    # Enable memory growth\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "else:\n",
    "    print(\"‚ùå No GPU found! Go to Runtime > Change runtime type > GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional libraries\n",
    "!pip install -q albumentations\n",
    "!pip install -q scikit-learn\n",
    "!pip install -q seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import json\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# TensorFlow & Keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model, Sequential\n",
    "from tensorflow.keras.applications import (\n",
    "    MobileNetV2,\n",
    "    EfficientNetB0,\n",
    "    EfficientNetB3,\n",
    "    ResNet50V2,\n",
    "    InceptionV3,\n",
    "    Xception\n",
    ")\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping, \n",
    "    ModelCheckpoint, \n",
    "    ReduceLROnPlateau, \n",
    "    TensorBoard,\n",
    "    LearningRateScheduler\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam, AdamW\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy, AUC\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_curve, \n",
    "    auc,\n",
    "    precision_recall_curve\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Albumentations for advanced augmentation\n",
    "import albumentations as A\n",
    "\n",
    "print(\"\\n‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFIGURATION - MODIFY THESE PATHS\n",
    "# ============================================\n",
    "\n",
    "# Option 1: Google Drive path\n",
    "# DATA_DIR = Path('/content/drive/MyDrive/CoconutML/data/raw/pest')\n",
    "# MODEL_DIR = Path('/content/drive/MyDrive/CoconutML/models/coconut_mite')\n",
    "\n",
    "# Option 2: Local path (if uploaded to Colab)\n",
    "DATA_DIR = Path('../data/raw/pest')\n",
    "MODEL_DIR = Path('../models/coconut_mite')\n",
    "\n",
    "# ============================================\n",
    "# MODEL CONFIGURATION\n",
    "# ============================================\n",
    "CONFIG = {\n",
    "    # Image settings\n",
    "    'img_size': 224,           # Image size (224 for MobileNet/EfficientNet, 299 for Inception/Xception)\n",
    "    'channels': 3,\n",
    "    \n",
    "    # Training settings\n",
    "    'batch_size': 32,          # Reduce if OOM error\n",
    "    'epochs': 100,             # Will early stop anyway\n",
    "    'learning_rate': 1e-4,\n",
    "    'min_lr': 1e-7,\n",
    "    \n",
    "    # Data split\n",
    "    'test_split': 0.15,        # 15% for final testing\n",
    "    'val_split': 0.15,         # 15% for validation\n",
    "    \n",
    "    # Cross validation\n",
    "    'use_kfold': False,        # Set True for K-Fold CV\n",
    "    'n_folds': 5,\n",
    "    \n",
    "    # Classes\n",
    "    'classes': ['coconut_mite', 'healthy'],\n",
    "    'num_classes': 2,\n",
    "    \n",
    "    # Seed for reproducibility\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(CONFIG['seed'])\n",
    "tf.random.set_seed(CONFIG['seed'])\n",
    "random.seed(CONFIG['seed'])\n",
    "\n",
    "# Create directories\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_dir, classes):\n",
    "    \"\"\"Load image paths and labels\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for class_idx, class_name in enumerate(classes):\n",
    "        class_dir = data_dir / class_name\n",
    "        if not class_dir.exists():\n",
    "            print(f\"‚ö†Ô∏è Warning: {class_dir} does not exist!\")\n",
    "            continue\n",
    "            \n",
    "        for img_path in class_dir.glob('*'):\n",
    "            if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "                images.append(str(img_path))\n",
    "                labels.append(class_idx)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_dataset(DATA_DIR, CONFIG['classes'])\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nTotal images: {len(X):,}\")\n",
    "for idx, class_name in enumerate(CONFIG['classes']):\n",
    "    count = np.sum(y == idx)\n",
    "    print(f\"  {class_name}: {count:,} ({count/len(X)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Val/Test Split\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=CONFIG['test_split'], \n",
    "    stratify=y, \n",
    "    random_state=CONFIG['seed']\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, \n",
    "    test_size=CONFIG['val_split']/(1-CONFIG['test_split']), \n",
    "    stratify=y_temp, \n",
    "    random_state=CONFIG['seed']\n",
    ")\n",
    "\n",
    "print(f\"\\nData Split:\")\n",
    "print(f\"  Training:   {len(X_train):,} images\")\n",
    "print(f\"  Validation: {len(X_val):,} images\")\n",
    "print(f\"  Test:       {len(X_test):,} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(f\"\\nClass weights: {class_weights_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albumentations augmentation pipeline\n",
    "def get_augmentation(mode='train'):\n",
    "    \"\"\"Get augmentation pipeline\"\"\"\n",
    "    \n",
    "    if mode == 'train':\n",
    "        return A.Compose([\n",
    "            A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "            \n",
    "            # Geometric transforms\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.3),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.ShiftScaleRotate(\n",
    "                shift_limit=0.1, \n",
    "                scale_limit=0.2, \n",
    "                rotate_limit=30, \n",
    "                p=0.5\n",
    "            ),\n",
    "            \n",
    "            # Color transforms\n",
    "            A.OneOf([\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1),\n",
    "                A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=1),\n",
    "                A.ColorJitter(p=1),\n",
    "            ], p=0.5),\n",
    "            \n",
    "            # Blur & Noise\n",
    "            A.OneOf([\n",
    "                A.GaussianBlur(blur_limit=(3, 5), p=1),\n",
    "                A.GaussNoise(var_limit=(10, 50), p=1),\n",
    "                A.ISONoise(p=1),\n",
    "            ], p=0.3),\n",
    "            \n",
    "            # Advanced\n",
    "            A.CoarseDropout(\n",
    "                max_holes=8, \n",
    "                max_height=CONFIG['img_size']//8,\n",
    "                max_width=CONFIG['img_size']//8,\n",
    "                fill_value=0, \n",
    "                p=0.3\n",
    "            ),\n",
    "            \n",
    "            # Normalize\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "        ])\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "print(\"‚úÖ Augmentation pipelines created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generator class\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, image_paths, labels, batch_size, augmentation, num_classes, shuffle=True):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.augmentation = augmentation\n",
    "        self.num_classes = num_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.image_paths))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_paths = self.image_paths[batch_indexes]\n",
    "        batch_labels = self.labels[batch_indexes]\n",
    "        \n",
    "        X = np.zeros((len(batch_paths), CONFIG['img_size'], CONFIG['img_size'], 3), dtype=np.float32)\n",
    "        y = keras.utils.to_categorical(batch_labels, num_classes=self.num_classes)\n",
    "        \n",
    "        for i, path in enumerate(batch_paths):\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            augmented = self.augmentation(image=img)\n",
    "            X[i] = augmented['image']\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "# Create generators\n",
    "train_gen = DataGenerator(\n",
    "    X_train, y_train, \n",
    "    CONFIG['batch_size'], \n",
    "    get_augmentation('train'),\n",
    "    CONFIG['num_classes'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = DataGenerator(\n",
    "    X_val, y_val,\n",
    "    CONFIG['batch_size'],\n",
    "    get_augmentation('val'),\n",
    "    CONFIG['num_classes'],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_gen = DataGenerator(\n",
    "    X_test, y_test,\n",
    "    CONFIG['batch_size'],\n",
    "    get_augmentation('val'),\n",
    "    CONFIG['num_classes'],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Data generators created!\")\n",
    "print(f\"  Training batches: {len(train_gen)}\")\n",
    "print(f\"  Validation batches: {len(val_gen)}\")\n",
    "print(f\"  Test batches: {len(test_gen)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize augmented samples\n",
    "sample_img_path = X_train[0]\n",
    "sample_img = cv2.imread(sample_img_path)\n",
    "sample_img = cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "aug = get_augmentation('train')\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "axes[0].imshow(cv2.resize(sample_img, (CONFIG['img_size'], CONFIG['img_size'])))\n",
    "axes[0].set_title('Original', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "for i in range(1, 8):\n",
    "    augmented = aug(image=sample_img)['image']\n",
    "    # Denormalize for visualization\n",
    "    img_show = augmented * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    img_show = np.clip(img_show, 0, 1)\n",
    "    axes[i].imshow(img_show)\n",
    "    axes[i].set_title(f'Augmented {i}', fontsize=11)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Data Augmentation Examples', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Architecture Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(backbone_name, input_shape, num_classes, dropout_rate=0.5):\n",
    "    \"\"\"\n",
    "    Create a transfer learning model with specified backbone\n",
    "    \"\"\"\n",
    "    \n",
    "    # Backbone selection\n",
    "    backbones = {\n",
    "        'MobileNetV2': MobileNetV2,\n",
    "        'EfficientNetB0': EfficientNetB0,\n",
    "        'EfficientNetB3': EfficientNetB3,\n",
    "        'ResNet50V2': ResNet50V2,\n",
    "        'InceptionV3': InceptionV3,\n",
    "        'Xception': Xception\n",
    "    }\n",
    "    \n",
    "    if backbone_name not in backbones:\n",
    "        raise ValueError(f\"Unknown backbone: {backbone_name}\")\n",
    "    \n",
    "    # Load base model\n",
    "    base_model = backbones[backbone_name](\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Freeze base model\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build model\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    \n",
    "    # Global pooling + classification head\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01))(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01))(x)\n",
    "    x = layers.Dropout(dropout_rate * 0.6)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs, name=f'{backbone_name}_classifier')\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "print(\"‚úÖ Model creation function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler\n",
    "def cosine_annealing_schedule(epoch, lr, total_epochs=100, min_lr=1e-7):\n",
    "    \"\"\"Cosine annealing with warm restarts\"\"\"\n",
    "    return min_lr + (lr - min_lr) * (1 + np.cos(np.pi * epoch / total_epochs)) / 2\n",
    "\n",
    "def get_callbacks(model_name, patience=15):\n",
    "    \"\"\"Get training callbacks\"\"\"\n",
    "    return [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=patience,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            filepath=str(MODEL_DIR / f'{model_name}_best.keras'),\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=CONFIG['min_lr'],\n",
    "            verbose=1\n",
    "        ),\n",
    "        LearningRateScheduler(\n",
    "            lambda epoch, lr: cosine_annealing_schedule(epoch, CONFIG['learning_rate'], CONFIG['epochs']),\n",
    "            verbose=0\n",
    "        )\n",
    "    ]\n",
    "\n",
    "print(\"‚úÖ Callbacks configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train Multiple Models & Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select models to compare\n",
    "# Comment out models you don't want to train\n",
    "MODELS_TO_TRAIN = [\n",
    "    'EfficientNetB0',     # Best balance of accuracy and size\n",
    "    # 'EfficientNetB3',   # Higher accuracy, larger model\n",
    "    # 'MobileNetV2',      # Fastest, good for mobile\n",
    "    # 'ResNet50V2',       # Classic, very accurate\n",
    "    # 'Xception',         # Very accurate, larger model\n",
    "]\n",
    "\n",
    "print(f\"Models to train: {MODELS_TO_TRAIN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(backbone_name, train_gen, val_gen, class_weights, epochs=100):\n",
    "    \"\"\"Train a model with 2-phase training\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"TRAINING: {backbone_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    input_shape = (CONFIG['img_size'], CONFIG['img_size'], 3)\n",
    "    model, base_model = create_model(backbone_name, input_shape, CONFIG['num_classes'])\n",
    "    \n",
    "    # Phase 1: Train classification head only\n",
    "    print(\"\\nüìå Phase 1: Training classification head...\")\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=CONFIG['learning_rate']),\n",
    "        loss=CategoricalCrossentropy(label_smoothing=0.1),\n",
    "        metrics=['accuracy', AUC(name='auc')]\n",
    "    )\n",
    "    \n",
    "    history1 = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=20,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=get_callbacks(f'{backbone_name}_phase1', patience=10),\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Phase 2: Fine-tune top layers\n",
    "    print(\"\\nüìå Phase 2: Fine-tuning top layers...\")\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    # Freeze early layers\n",
    "    fine_tune_from = int(len(base_model.layers) * 0.7)  # Unfreeze top 30%\n",
    "    for layer in base_model.layers[:fine_tune_from]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=CONFIG['learning_rate'] / 10),\n",
    "        loss=CategoricalCrossentropy(label_smoothing=0.1),\n",
    "        metrics=['accuracy', AUC(name='auc')]\n",
    "    )\n",
    "    \n",
    "    history2 = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=epochs,\n",
    "        initial_epoch=len(history1.history['loss']),\n",
    "        class_weight=class_weights,\n",
    "        callbacks=get_callbacks(f'{backbone_name}_phase2', patience=15),\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Combine histories\n",
    "    history = {}\n",
    "    for key in history1.history.keys():\n",
    "        history[key] = history1.history[key] + history2.history[key]\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "print(\"‚úÖ Training function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all selected models\n",
    "results = {}\n",
    "\n",
    "for backbone in MODELS_TO_TRAIN:\n",
    "    model, history = train_model(\n",
    "        backbone, \n",
    "        train_gen, \n",
    "        val_gen, \n",
    "        class_weights_dict,\n",
    "        epochs=CONFIG['epochs']\n",
    "    )\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loss, test_acc, test_auc = model.evaluate(test_gen, verbose=0)\n",
    "    \n",
    "    results[backbone] = {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'test_loss': test_loss,\n",
    "        'test_accuracy': test_acc,\n",
    "        'test_auc': test_auc\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n‚úÖ {backbone} - Test Accuracy: {test_acc*100:.2f}%, Test AUC: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Test Accuracy': [r['test_accuracy']*100 for r in results.values()],\n",
    "    'Test AUC': [r['test_auc'] for r in results.values()],\n",
    "    'Test Loss': [r['test_loss'] for r in results.values()]\n",
    "}).sort_values('Test Accuracy', ascending=False)\n",
    "\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Best model\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_accuracy = comparison_df.iloc[0]['Test Accuracy']\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name} with {best_accuracy:.2f}% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Detailed Evaluation of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_model = results[best_model_name]['model']\n",
    "best_history = results[best_model_name]['history']\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(best_history['accuracy'], label='Train', linewidth=2)\n",
    "axes[0].plot(best_history['val_accuracy'], label='Validation', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title(f'{best_model_name} - Accuracy', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(best_history['loss'], label='Train', linewidth=2)\n",
    "axes[1].plot(best_history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title(f'{best_model_name} - Loss', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# AUC\n",
    "axes[2].plot(best_history['auc'], label='Train', linewidth=2)\n",
    "axes[2].plot(best_history['val_auc'], label='Validation', linewidth=2)\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('AUC')\n",
    "axes[2].set_title(f'{best_model_name} - AUC', fontsize=12, fontweight='bold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODEL_DIR / 'training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "y_pred_proba = best_model.predict(test_gen, verbose=1)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "y_true = y_test\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_true, y_pred, target_names=CONFIG['classes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Raw counts\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=CONFIG['classes'], yticklabels=CONFIG['classes'])\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_title('Confusion Matrix (Counts)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Normalized\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Blues', ax=axes[1],\n",
    "            xticklabels=CONFIG['classes'], yticklabels=CONFIG['classes'])\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "axes[1].set_title('Confusion Matrix (Normalized)', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODEL_DIR / 'confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve & Precision-Recall Curve\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred_proba[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "axes[0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "axes[0].set_xlim([0.0, 1.0])\n",
    "axes[0].set_ylim([0.0, 1.05])\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('ROC Curve', fontsize=12, fontweight='bold')\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_pred_proba[:, 1])\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "axes[1].plot(recall, precision, color='green', lw=2, label=f'PR curve (AUC = {pr_auc:.4f})')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('Recall')\n",
    "axes[1].set_ylabel('Precision')\n",
    "axes[1].set_title('Precision-Recall Curve', fontsize=12, fontweight='bold')\n",
    "axes[1].legend(loc='lower left')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODEL_DIR / 'roc_pr_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in multiple formats\n",
    "print(\"=\"*60)\n",
    "print(\"SAVING BEST MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Keras format\n",
    "best_model.save(MODEL_DIR / 'coconut_mite_best.keras')\n",
    "print(f\"‚úÖ Keras model saved: {MODEL_DIR / 'coconut_mite_best.keras'}\")\n",
    "\n",
    "# H5 format\n",
    "best_model.save(MODEL_DIR / 'coconut_mite_best.h5')\n",
    "print(f\"‚úÖ H5 model saved: {MODEL_DIR / 'coconut_mite_best.h5'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TensorFlow Lite (optimized for mobile)\n",
    "print(\"\\nConverting to TensorFlow Lite...\")\n",
    "\n",
    "# Standard TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_path = MODEL_DIR / 'coconut_mite_model.tflite'\n",
    "with open(tflite_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "print(f\"‚úÖ TFLite model saved: {tflite_path}\")\n",
    "print(f\"   Size: {os.path.getsize(tflite_path) / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Quantized TFLite (smaller, faster)\n",
    "converter_quant = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
    "converter_quant.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter_quant.target_spec.supported_types = [tf.float16]\n",
    "tflite_quant_model = converter_quant.convert()\n",
    "\n",
    "tflite_quant_path = MODEL_DIR / 'coconut_mite_model_quantized.tflite'\n",
    "with open(tflite_quant_path, 'wb') as f:\n",
    "    f.write(tflite_quant_model)\n",
    "print(f\"‚úÖ Quantized TFLite saved: {tflite_quant_path}\")\n",
    "print(f\"   Size: {os.path.getsize(tflite_quant_path) / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model metadata\n",
    "model_info = {\n",
    "    'model_name': best_model_name,\n",
    "    'input_shape': [CONFIG['img_size'], CONFIG['img_size'], 3],\n",
    "    'classes': CONFIG['classes'],\n",
    "    'class_indices': {c: i for i, c in enumerate(CONFIG['classes'])},\n",
    "    'test_accuracy': float(results[best_model_name]['test_accuracy']),\n",
    "    'test_auc': float(results[best_model_name]['test_auc']),\n",
    "    'normalization': {\n",
    "        'mean': [0.485, 0.456, 0.406],\n",
    "        'std': [0.229, 0.224, 0.225]\n",
    "    },\n",
    "    'training_date': datetime.datetime.now().isoformat(),\n",
    "    'version': '2.0.0'\n",
    "}\n",
    "\n",
    "with open(MODEL_DIR / 'model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Model info saved: {MODEL_DIR / 'model_info.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(model, image_path, class_names):\n",
    "    \"\"\"Predict a single image\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Preprocess\n",
    "    aug = get_augmentation('val')\n",
    "    augmented = aug(image=img)['image']\n",
    "    img_batch = np.expand_dims(augmented, axis=0)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict(img_batch, verbose=0)\n",
    "    pred_class = np.argmax(predictions[0])\n",
    "    confidence = predictions[0][pred_class]\n",
    "    \n",
    "    return class_names[pred_class], confidence, img\n",
    "\n",
    "# Test with random samples\n",
    "n_samples = 6\n",
    "test_samples = np.random.choice(X_test, n_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, img_path in enumerate(test_samples):\n",
    "    pred_class, confidence, img = predict_single_image(best_model, img_path, CONFIG['classes'])\n",
    "    true_class = CONFIG['classes'][y_test[np.where(X_test == img_path)[0][0]]]\n",
    "    \n",
    "    img_resized = cv2.resize(img, (CONFIG['img_size'], CONFIG['img_size']))\n",
    "    axes[idx].imshow(img_resized)\n",
    "    \n",
    "    color = 'green' if pred_class == true_class else 'red'\n",
    "    axes[idx].set_title(\n",
    "        f'Pred: {pred_class} ({confidence:.1%})\\nTrue: {true_class}',\n",
    "        fontsize=11, color=color, fontweight='bold'\n",
    "    )\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Test Predictions', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(MODEL_DIR / 'sample_predictions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä RESULTS SUMMARY\n",
    "{'‚îÄ'*40}\n",
    "Best Model:      {best_model_name}\n",
    "Test Accuracy:   {results[best_model_name]['test_accuracy']*100:.2f}%\n",
    "Test AUC:        {results[best_model_name]['test_auc']:.4f}\n",
    "ROC AUC:         {roc_auc:.4f}\n",
    "PR AUC:          {pr_auc:.4f}\n",
    "\n",
    "üìÅ SAVED FILES\n",
    "{'‚îÄ'*40}\n",
    "‚Ä¢ coconut_mite_best.keras       - Full Keras model\n",
    "‚Ä¢ coconut_mite_best.h5          - H5 format\n",
    "‚Ä¢ coconut_mite_model.tflite     - TensorFlow Lite\n",
    "‚Ä¢ coconut_mite_model_quantized.tflite - Quantized (smaller)\n",
    "‚Ä¢ model_info.json               - Model metadata\n",
    "‚Ä¢ training_history.png          - Training curves\n",
    "‚Ä¢ confusion_matrix.png          - Evaluation results\n",
    "‚Ä¢ roc_pr_curves.png             - ROC & PR curves\n",
    "\n",
    "üöÄ NEXT STEPS\n",
    "{'‚îÄ'*40}\n",
    "1. Deploy model via Flask API\n",
    "2. Integrate TFLite with React Native app\n",
    "3. Train models for other pest types\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
