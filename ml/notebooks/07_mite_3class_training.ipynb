{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü•• Coconut Mite Detection - 3-Class Model (v8)\n",
    "\n",
    "## Model Overview\n",
    "This notebook implements a **3-class image classification model** to detect coconut mite infection with **out-of-scope rejection**.\n",
    "\n",
    "| Parameter | Value |\n",
    "|-----------|-------|\n",
    "| **Model Architecture** | EfficientNetB0 (Transfer Learning) |\n",
    "| **Framework** | TensorFlow 2.x / Keras |\n",
    "| **Task** | Multi-class Classification (3 classes) |\n",
    "| **Classes** | coconut_mite, healthy, not_coconut |\n",
    "| **Input Size** | 224 x 224 x 3 (RGB) |\n",
    "| **Improvement** | Can reject non-coconut images |\n",
    "\n",
    "---\n",
    "**Author:** Research Team  \n",
    "**Date:** 2025-12-24  \n",
    "**Version:** v8 (3-class with out-of-scope detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# Deep Learning - TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Scikit-learn Metrics\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    precision_recall_fscore_support,\n",
    "    accuracy_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# Utilities\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Display versions\n",
    "print(\"=\" * 60)\n",
    "print(\"  ENVIRONMENT SETUP\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"  NumPy Version: {np.__version__}\")\n",
    "print(f\"  GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(f\"  GPU Device: {tf.config.list_physical_devices('GPU')[0]}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Configuration & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PATH CONFIGURATION\n",
    "# ============================================================\n",
    "BASE_DIR = os.path.dirname(os.getcwd())\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data', 'raw', 'pest_mite', 'dataset_v3_clean')\n",
    "MODEL_DIR = os.path.join(BASE_DIR, 'models', 'coconut_mite_v8')\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "VAL_DIR = os.path.join(DATA_DIR, 'validation')\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'test')\n",
    "\n",
    "# ============================================================\n",
    "# HYPERPARAMETERS (Anti-Overfitting Configuration)\n",
    "# ============================================================\n",
    "IMG_SIZE = 224          # EfficientNetB0 default input size\n",
    "BATCH_SIZE = 32         # Training batch size\n",
    "EPOCHS = 50             # Maximum training epochs\n",
    "LEARNING_RATE = 0.0001  # Adam optimizer learning rate\n",
    "DROPOUT_RATE = 0.6      # Dropout for regularization (increased)\n",
    "L2_REG = 0.02           # L2 regularization strength\n",
    "LABEL_SMOOTHING = 0.1   # Label smoothing for better generalization\n",
    "PATIENCE = 5            # Early stopping patience (earlier stop)\n",
    "\n",
    "# Class names - NOW 3 CLASSES!\n",
    "CLASS_NAMES = ['coconut_mite', 'healthy', 'not_coconut']\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# Create model directory\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  CONFIGURATION - 3-CLASS MODEL (v8)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n  [Paths]\")\n",
    "print(f\"    Data Directory:  {DATA_DIR}\")\n",
    "print(f\"    Model Directory: {MODEL_DIR}\")\n",
    "print(f\"\\n  [Hyperparameters - Anti-Overfitting]\")\n",
    "print(f\"    Image Size:      {IMG_SIZE} x {IMG_SIZE} x 3\")\n",
    "print(f\"    Batch Size:      {BATCH_SIZE}\")\n",
    "print(f\"    Max Epochs:      {EPOCHS}\")\n",
    "print(f\"    Learning Rate:   {LEARNING_RATE}\")\n",
    "print(f\"    Dropout Rate:    {DROPOUT_RATE} (high for anti-overfit)\")\n",
    "print(f\"    L2 Regularization: {L2_REG}\")\n",
    "print(f\"    Label Smoothing: {LABEL_SMOOTHING}\")\n",
    "print(f\"    Early Stop:      {PATIENCE} epochs\")\n",
    "print(f\"\\n  [Classification]\")\n",
    "print(f\"    Task:            3-Class Classification\")\n",
    "print(f\"    Classes:         {CLASS_NAMES}\")\n",
    "print(f\"    Output:          Softmax (3 neurons)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Dataset Loading & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# COUNT IMAGES IN EACH SPLIT\n",
    "# ============================================================\n",
    "def count_images(directory):\n",
    "    \"\"\"Count images in each class folder.\"\"\"\n",
    "    counts = {}\n",
    "    for class_name in CLASS_NAMES:\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        if os.path.exists(class_dir):\n",
    "            counts[class_name] = len([f for f in os.listdir(class_dir) \n",
    "                                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        else:\n",
    "            counts[class_name] = 0\n",
    "    return counts\n",
    "\n",
    "train_counts = count_images(TRAIN_DIR)\n",
    "val_counts = count_images(VAL_DIR)\n",
    "test_counts = count_images(TEST_DIR)\n",
    "\n",
    "# Create summary dataframe\n",
    "dataset_summary = pd.DataFrame({\n",
    "    'Split': ['Train', 'Validation', 'Test', 'Total'],\n",
    "    'coconut_mite': [train_counts['coconut_mite'], val_counts['coconut_mite'], \n",
    "                    test_counts['coconut_mite'], \n",
    "                    train_counts['coconut_mite'] + val_counts['coconut_mite'] + test_counts['coconut_mite']],\n",
    "    'healthy': [train_counts['healthy'], val_counts['healthy'], \n",
    "                test_counts['healthy'], \n",
    "                train_counts['healthy'] + val_counts['healthy'] + test_counts['healthy']],\n",
    "    'not_coconut': [train_counts['not_coconut'], val_counts['not_coconut'], \n",
    "                    test_counts['not_coconut'], \n",
    "                    train_counts['not_coconut'] + val_counts['not_coconut'] + test_counts['not_coconut']],\n",
    "    'Total': [sum(train_counts.values()), sum(val_counts.values()), \n",
    "              sum(test_counts.values()), \n",
    "              sum(train_counts.values()) + sum(val_counts.values()) + sum(test_counts.values())]\n",
    "})\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"  DATASET SUMMARY - 3 CLASSES\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n{dataset_summary.to_string(index=False)}\")\n",
    "print(f\"\\n  NEW: not_coconut class added for out-of-scope detection!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Visualize Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZE CLASS DISTRIBUTION\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "colors = ['#e74c3c', '#2ecc71', '#3498db']  # Red, Green, Blue\n",
    "\n",
    "# Training distribution\n",
    "train_vals = [train_counts['coconut_mite'], train_counts['healthy'], train_counts['not_coconut']]\n",
    "axes[0].bar(CLASS_NAMES, train_vals, color=colors, edgecolor='black')\n",
    "axes[0].set_title('Training Set Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Number of Images')\n",
    "axes[0].tick_params(axis='x', rotation=15)\n",
    "for i, v in enumerate(train_vals):\n",
    "    axes[0].text(i, v + 50, f'{v:,}', ha='center', fontweight='bold')\n",
    "\n",
    "# Validation distribution\n",
    "val_vals = [val_counts['coconut_mite'], val_counts['healthy'], val_counts['not_coconut']]\n",
    "axes[1].bar(CLASS_NAMES, val_vals, color=colors, edgecolor='black')\n",
    "axes[1].set_title('Validation Set Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Number of Images')\n",
    "axes[1].tick_params(axis='x', rotation=15)\n",
    "for i, v in enumerate(val_vals):\n",
    "    axes[1].text(i, v + 5, f'{v}', ha='center', fontweight='bold')\n",
    "\n",
    "# Test distribution\n",
    "test_vals = [test_counts['coconut_mite'], test_counts['healthy'], test_counts['not_coconut']]\n",
    "axes[2].bar(CLASS_NAMES, test_vals, color=colors, edgecolor='black')\n",
    "axes[2].set_title('Test Set Distribution', fontsize=12, fontweight='bold')\n",
    "axes[2].set_ylabel('Number of Images')\n",
    "axes[2].tick_params(axis='x', rotation=15)\n",
    "for i, v in enumerate(test_vals):\n",
    "    axes[2].text(i, v + 5, f'{v}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'dataset_distribution.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Dataset distribution chart saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Distribution Pie Chart\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "total_per_class = [\n",
    "    train_counts['coconut_mite'] + val_counts['coconut_mite'] + test_counts['coconut_mite'],\n",
    "    train_counts['healthy'] + val_counts['healthy'] + test_counts['healthy'],\n",
    "    train_counts['not_coconut'] + val_counts['not_coconut'] + test_counts['not_coconut']\n",
    "]\n",
    "\n",
    "explode = (0.02, 0.02, 0.05)  # Highlight not_coconut\n",
    "ax.pie(total_per_class, explode=explode, labels=CLASS_NAMES, colors=colors,\n",
    "       autopct='%1.1f%%', shadow=True, startangle=90,\n",
    "       textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "ax.set_title(f'Overall Class Distribution\\n(Total: {sum(total_per_class):,} images)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'class_distribution_pie.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Display Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DISPLAY SAMPLE IMAGES FROM EACH CLASS\n",
    "# ============================================================\n",
    "def display_samples_3class(n_samples=5):\n",
    "    \"\"\"Display sample images from all 3 classes.\"\"\"\n",
    "    fig, axes = plt.subplots(3, n_samples, figsize=(15, 10))\n",
    "    \n",
    "    titles = ['üî¥ COCONUT MITE (Infected)', 'üü¢ HEALTHY', 'üîµ NOT COCONUT (Out-of-scope)']\n",
    "    title_colors = ['#e74c3c', '#2ecc71', '#3498db']\n",
    "    \n",
    "    for row, (cls, title, color) in enumerate(zip(CLASS_NAMES, titles, title_colors)):\n",
    "        class_dir = os.path.join(TRAIN_DIR, cls)\n",
    "        if not os.path.exists(class_dir):\n",
    "            print(f\"Directory not found: {class_dir}\")\n",
    "            continue\n",
    "            \n",
    "        images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:n_samples]\n",
    "        \n",
    "        for col, img_name in enumerate(images):\n",
    "            if col >= n_samples:\n",
    "                break\n",
    "            try:\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                img = Image.open(img_path)\n",
    "                axes[row, col].imshow(img)\n",
    "                axes[row, col].axis('off')\n",
    "                if col == 0:\n",
    "                    axes[row, col].set_title(title, fontsize=11, fontweight='bold', color=color, loc='left')\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "    \n",
    "    plt.suptitle('Sample Images from Each Class', fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(MODEL_DIR, 'sample_images.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "display_samples_3class(n_samples=5)\n",
    "print(\"\\n‚úì Sample images saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Data Preprocessing & Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATA AUGMENTATION CONFIGURATION (Stronger for Anti-Overfitting)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  DATA AUGMENTATION CONFIGURATION (Anti-Overfitting)\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n  [Training Augmentation - STRONG]\")\n",
    "print(\"    ‚Ä¢ Rescale: 1/255 (normalize to [0,1])\")\n",
    "print(\"    ‚Ä¢ Rotation: ¬±30¬∞\")\n",
    "print(\"    ‚Ä¢ Width Shift: ¬±20%\")\n",
    "print(\"    ‚Ä¢ Height Shift: ¬±20%\")\n",
    "print(\"    ‚Ä¢ Shear: 20%\")\n",
    "print(\"    ‚Ä¢ Zoom: ¬±20%\")\n",
    "print(\"    ‚Ä¢ Horizontal Flip: Yes\")\n",
    "print(\"    ‚Ä¢ Brightness: ¬±20%\")\n",
    "print(\"\\n  [Validation/Test]\")\n",
    "print(\"    ‚Ä¢ Rescale: 1/255 only (no augmentation)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CREATE DATA GENERATORS\n",
    "# ============================================================\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Training data generator - WITH strong augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation & Test data generator - NO augmentation\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',  # Changed to categorical for 3-class\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  DATA GENERATORS CREATED (3-CLASS)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n  Training Generator:\")\n",
    "print(f\"    Samples: {train_generator.samples}\")\n",
    "print(f\"    Batches: {len(train_generator)}\")\n",
    "print(f\"    Classes: {train_generator.class_indices}\")\n",
    "print(f\"\\n  Validation Generator:\")\n",
    "print(f\"    Samples: {val_generator.samples}\")\n",
    "print(f\"\\n  Test Generator:\")\n",
    "print(f\"    Samples: {test_generator.samples}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Model Architecture - EfficientNetB0 (3-Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MODEL ARCHITECTURE\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  MODEL ARCHITECTURE - 3-CLASS CLASSIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "  BASE MODEL: EfficientNetB0\n",
    "  ‚îú‚îÄ‚îÄ Pre-trained on ImageNet (1.4M images, 1000 classes)\n",
    "  ‚îú‚îÄ‚îÄ Efficient compound scaling\n",
    "  ‚îî‚îÄ‚îÄ Status: Frozen (not trainable)\n",
    "  \n",
    "  CUSTOM CLASSIFICATION HEAD (Anti-Overfitting):\n",
    "  ‚îú‚îÄ‚îÄ GlobalAveragePooling2D\n",
    "  ‚îÇ   ‚îî‚îÄ‚îÄ Reduces spatial dimensions\n",
    "  ‚îú‚îÄ‚îÄ BatchNormalization\n",
    "  ‚îÇ   ‚îî‚îÄ‚îÄ Stabilizes training\n",
    "  ‚îú‚îÄ‚îÄ Dense(32, relu, L2=0.02)  ‚Üê Smaller (anti-overfit)\n",
    "  ‚îÇ   ‚îî‚îÄ‚îÄ Feature extraction\n",
    "  ‚îú‚îÄ‚îÄ Dropout(0.6)  ‚Üê Higher (anti-overfit)\n",
    "  ‚îÇ   ‚îî‚îÄ‚îÄ Prevents overfitting\n",
    "  ‚îî‚îÄ‚îÄ Dense(3, softmax)  ‚Üê 3 CLASSES NOW!\n",
    "      ‚îî‚îÄ‚îÄ Multi-class classification output\n",
    "  \n",
    "  COMPILATION:\n",
    "  ‚îú‚îÄ‚îÄ Optimizer: Adam (lr=0.0001)\n",
    "  ‚îú‚îÄ‚îÄ Loss: Categorical Crossentropy (label_smoothing=0.1)\n",
    "  ‚îî‚îÄ‚îÄ Metrics: Accuracy\n",
    "\"\"\")\n",
    "\n",
    "print(\"  KEY CHANGES from v7 (2-class):\")\n",
    "print(\"    ‚Ä¢ Output: 3 neurons (softmax) instead of 1 (sigmoid)\")\n",
    "print(\"    ‚Ä¢ Loss: categorical_crossentropy instead of binary\")\n",
    "print(\"    ‚Ä¢ NEW CLASS: not_coconut for out-of-scope rejection\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BUILD THE MODEL\n",
    "# ============================================================\n",
    "\n",
    "def build_3class_model():\n",
    "    \"\"\"Build EfficientNetB0 model for 3-class classification.\"\"\"\n",
    "    \n",
    "    # Load pre-trained EfficientNetB0\n",
    "    base_model = EfficientNetB0(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "    \n",
    "    # Freeze base model\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build custom head\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(32, activation='relu', kernel_regularizer=l2(L2_REG))(x)  # Smaller dense\n",
    "    x = Dropout(DROPOUT_RATE)(x)  # Higher dropout\n",
    "    \n",
    "    # Output layer - 3 classes with softmax\n",
    "    outputs = Dense(NUM_CLASSES, activation='softmax', name='output')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=base_model.input, outputs=outputs)\n",
    "    \n",
    "    # Compile with label smoothing\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTHING),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "model = build_3class_model()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  MODEL BUILT SUCCESSFULLY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n  Total Parameters: {model.count_params():,}\")\n",
    "trainable = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
    "print(f\"  Trainable Parameters: {trainable:,}\")\n",
    "print(f\"  Non-trainable Parameters: {model.count_params() - trainable:,}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAINING CALLBACKS\n",
    "# ============================================================\n",
    "\n",
    "# Model checkpoint - save best model\n",
    "checkpoint = ModelCheckpoint(\n",
    "    os.path.join(MODEL_DIR, 'best_model.keras'),\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Early stopping - prevent overfitting\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=PATIENCE,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Reduce learning rate on plateau\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint, early_stop, reduce_lr]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  TRAINING CALLBACKS CONFIGURED\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n  1. ModelCheckpoint\")\n",
    "print(f\"     - Monitor: val_accuracy\")\n",
    "print(f\"     - Save: Best model only\")\n",
    "print(\"\\n  2. EarlyStopping\")\n",
    "print(f\"     - Monitor: val_accuracy\")\n",
    "print(f\"     - Patience: {PATIENCE} epochs (earlier stop for anti-overfit)\")\n",
    "print(\"\\n  3. ReduceLROnPlateau\")\n",
    "print(f\"     - Monitor: val_loss\")\n",
    "print(f\"     - Factor: 0.5\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Model Training üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAIN THE MODEL\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  üöÄ STARTING TRAINING - 3-CLASS MODEL\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n  Training samples: {train_generator.samples}\")\n",
    "print(f\"  Validation samples: {val_generator.samples}\")\n",
    "print(f\"  Epochs: {EPOCHS} (max)\")\n",
    "print(f\"  Early stopping: {PATIENCE} epochs patience\")\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "end_time = datetime.now()\n",
    "training_time = (end_time - start_time).total_seconds() / 60\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  ‚úÖ TRAINING COMPLETED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n  Total epochs: {len(history.history['accuracy'])}\")\n",
    "print(f\"  Training time: {training_time:.1f} minutes\")\n",
    "print(f\"  Best val_accuracy: {max(history.history['val_accuracy'])*100:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history\n",
    "history_dict = {\n",
    "    'accuracy': [float(x) for x in history.history['accuracy']],\n",
    "    'val_accuracy': [float(x) for x in history.history['val_accuracy']],\n",
    "    'loss': [float(x) for x in history.history['loss']],\n",
    "    'val_loss': [float(x) for x in history.history['val_loss']]\n",
    "}\n",
    "\n",
    "with open(os.path.join(MODEL_DIR, 'training_history.json'), 'w') as f:\n",
    "    json.dump(history_dict, f, indent=2)\n",
    "\n",
    "print(\"‚úì Training history saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PLOT TRAINING HISTORY\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "epochs_range = range(1, len(history.history['accuracy']) + 1)\n",
    "\n",
    "# Plot 1: Accuracy\n",
    "axes[0].plot(epochs_range, [x*100 for x in history.history['accuracy']], 'b-', \n",
    "             label='Training Accuracy', linewidth=2, marker='o', markersize=4)\n",
    "axes[0].plot(epochs_range, [x*100 for x in history.history['val_accuracy']], 'r-', \n",
    "             label='Validation Accuracy', linewidth=2, marker='s', markersize=4)\n",
    "\n",
    "# Mark best epoch\n",
    "best_epoch = np.argmax(history.history['val_accuracy']) + 1\n",
    "best_val_acc = max(history.history['val_accuracy']) * 100\n",
    "axes[0].axvline(x=best_epoch, color='green', linestyle='--', alpha=0.7)\n",
    "axes[0].scatter([best_epoch], [best_val_acc], color='green', s=100, zorder=5)\n",
    "axes[0].annotate(f'Best: {best_val_acc:.1f}%\\n(Epoch {best_epoch})', \n",
    "                 xy=(best_epoch, best_val_acc), \n",
    "                 xytext=(best_epoch+1, best_val_acc-5), fontsize=10, color='green')\n",
    "\n",
    "axes[0].set_title('Model Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Calculate and display gap\n",
    "final_train_acc = history.history['accuracy'][-1] * 100\n",
    "final_val_acc = history.history['val_accuracy'][-1] * 100\n",
    "gap = abs(final_train_acc - final_val_acc)\n",
    "axes[0].annotate(f'Gap: {gap:.1f}%', xy=(len(epochs_range)-1, (final_train_acc+final_val_acc)/2),\n",
    "                 fontsize=11, color='purple', fontweight='bold')\n",
    "\n",
    "# Plot 2: Loss\n",
    "axes[1].plot(epochs_range, history.history['loss'], 'b-', \n",
    "             label='Training Loss', linewidth=2, marker='o', markersize=4)\n",
    "axes[1].plot(epochs_range, history.history['val_loss'], 'r-', \n",
    "             label='Validation Loss', linewidth=2, marker='s', markersize=4)\n",
    "axes[1].set_title('Model Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Loss', fontsize=12)\n",
    "axes[1].legend(loc='upper right')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'training_history.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n=== OVERFITTING ANALYSIS ===\")\n",
    "print(f\"Final Train Accuracy: {final_train_acc:.2f}%\")\n",
    "print(f\"Final Val Accuracy: {final_val_acc:.2f}%\")\n",
    "print(f\"Train-Val Gap: {gap:.2f}%\")\n",
    "print(f\"Status: {'‚úì GOOD' if gap < 10 else '‚ö† CHECK'}\")\n",
    "print(\"\\n‚úì Training history plot saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Model Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EVALUATE MODEL ON TEST SET\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  MODEL EVALUATION ON TEST SET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get predictions\n",
    "test_generator.reset()\n",
    "y_probs = model.predict(test_generator, verbose=1)\n",
    "y_pred = np.argmax(y_probs, axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "print(f\"\\n  Test samples: {len(y_true)}\")\n",
    "print(f\"  Classes: {list(test_generator.class_indices.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CLASSIFICATION REPORT\n",
    "# ============================================================\n",
    "\n",
    "# Get class names in correct order\n",
    "class_names_ordered = list(test_generator.class_indices.keys())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_true, y_pred, target_names=class_names_ordered, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Comprehensive Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CALCULATE ALL PERFORMANCE METRICS\n",
    "# ============================================================\n",
    "\n",
    "# Basic metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Per-class metrics\n",
    "precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
    "\n",
    "# Macro averages\n",
    "macro_precision = np.mean(precision)\n",
    "macro_recall = np.mean(recall)\n",
    "macro_f1 = np.mean(f1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  COMPREHENSIVE PERFORMANCE METRICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n  [Overall Metrics]\")\n",
    "print(f\"    Accuracy:           {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"    Macro Precision:    {macro_precision:.4f}\")\n",
    "print(f\"    Macro Recall:       {macro_recall:.4f}\")\n",
    "print(f\"    Macro F1-Score:     {macro_f1:.4f}\")\n",
    "\n",
    "print(\"\\n  [Per-Class Metrics]\")\n",
    "print(\"-\"*60)\n",
    "for i, cls in enumerate(class_names_ordered):\n",
    "    pr_gap = abs(precision[i] - recall[i])\n",
    "    print(f\"\\n  {cls.upper()}:\")\n",
    "    print(f\"    Precision: {precision[i]:.4f} ({precision[i]*100:.2f}%)\")\n",
    "    print(f\"    Recall:    {recall[i]:.4f} ({recall[i]*100:.2f}%)\")\n",
    "    print(f\"    F1-Score:  {f1[i]:.4f} ({f1[i]*100:.2f}%)\")\n",
    "    print(f\"    Support:   {support[i]}\")\n",
    "    print(f\"    P-R Gap:   {pr_gap:.4f} {'‚úì BALANCED' if pr_gap < 0.10 else '‚ö† CHECK'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Madam's Requirements Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# UTHPALA MISS REQUIREMENTS CHECK\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  üìã UTHPALA MISS REQUIREMENTS CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_pass = True\n",
    "\n",
    "# Requirement 1: P/R/F1 should be close for each class\n",
    "print(\"\\n  [Requirement 1: P/R/F1 Balance per Class]\")\n",
    "print(\"  \" + \"-\"*50)\n",
    "for i, cls in enumerate(class_names_ordered):\n",
    "    p, r, f = precision[i], recall[i], f1[i]\n",
    "    gap = max(p, r, f) - min(p, r, f)\n",
    "    status = \"‚úì PASS\" if gap < 0.10 else \"‚úó FAIL\"\n",
    "    if gap >= 0.10:\n",
    "        all_pass = False\n",
    "    print(f\"    {cls}: P={p:.2f}, R={r:.2f}, F1={f:.2f} | Gap={gap:.4f} [{status}]\")\n",
    "\n",
    "# Requirement 2: Accuracy should equal F1\n",
    "print(\"\\n  [Requirement 2: Accuracy ‚âà F1-Score]\")\n",
    "print(\"  \" + \"-\"*50)\n",
    "acc_f1_diff = abs(accuracy - macro_f1)\n",
    "status2 = \"‚úì PASS\" if acc_f1_diff < 0.05 else \"‚úó FAIL\"\n",
    "if acc_f1_diff >= 0.05:\n",
    "    all_pass = False\n",
    "print(f\"    Accuracy: {accuracy:.4f}\")\n",
    "print(f\"    Macro F1: {macro_f1:.4f}\")\n",
    "print(f\"    Difference: {acc_f1_diff:.4f} [{status2}]\")\n",
    "\n",
    "# Requirement 3: Class F1 scores should be similar\n",
    "print(\"\\n  [Requirement 3: Class F1-Scores Similar]\")\n",
    "print(\"  \" + \"-\"*50)\n",
    "f1_max_diff = max(f1) - min(f1)\n",
    "status3 = \"‚úì PASS\" if f1_max_diff < 0.15 else \"‚úó FAIL\"\n",
    "if f1_max_diff >= 0.15:\n",
    "    all_pass = False\n",
    "for i, cls in enumerate(class_names_ordered):\n",
    "    print(f\"    {cls} F1: {f1[i]:.4f}\")\n",
    "print(f\"    Max Difference: {f1_max_diff:.4f} [{status3}]\")\n",
    "\n",
    "# Requirement 4: Train-Val gap\n",
    "print(\"\\n  [Requirement 4: Train-Val Gap < 15%]\")\n",
    "print(\"  \" + \"-\"*50)\n",
    "train_val_gap = gap  # from earlier\n",
    "status4 = \"‚úì PASS\" if train_val_gap < 15 else \"‚úó FAIL\"\n",
    "if train_val_gap >= 15:\n",
    "    all_pass = False\n",
    "print(f\"    Train Accuracy: {final_train_acc:.2f}%\")\n",
    "print(f\"    Val Accuracy: {final_val_acc:.2f}%\")\n",
    "print(f\"    Gap: {train_val_gap:.2f}% [{status4}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if all_pass:\n",
    "    print(\"  ‚úÖ ALL REQUIREMENTS PASSED!\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è SOME REQUIREMENTS NEED ATTENTION\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Confusion Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFUSION MATRIX\n",
    "# ============================================================\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Raw counts\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=class_names_ordered,\n",
    "            yticklabels=class_names_ordered,\n",
    "            annot_kws={'size': 14})\n",
    "axes[0].set_title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[0].set_ylabel('True Label', fontsize=12)\n",
    "\n",
    "# Normalized (percentages)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues', ax=axes[1],\n",
    "            xticklabels=class_names_ordered,\n",
    "            yticklabels=class_names_ordered,\n",
    "            annot_kws={'size': 12})\n",
    "axes[1].set_title('Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[1].set_ylabel('True Label', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'confusion_matrix.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Confusion matrix saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 13. Per-Class Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PER-CLASS PERFORMANCE BAR CHART\n",
    "# ============================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(class_names_ordered))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax.bar(x - width, [p*100 for p in precision], width, label='Precision', color='#3498db', edgecolor='black')\n",
    "bars2 = ax.bar(x, [r*100 for r in recall], width, label='Recall', color='#2ecc71', edgecolor='black')\n",
    "bars3 = ax.bar(x + width, [f*100 for f in f1], width, label='F1-Score', color='#e74c3c', edgecolor='black')\n",
    "\n",
    "ax.set_ylabel('Score (%)', fontsize=12)\n",
    "ax.set_title('Per-Class Performance Metrics (3-Class Model)', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(class_names_ordered, fontsize=11)\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "ax.set_ylim([0, 110])\n",
    "ax.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2, bars3]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.1f}%', xy=(bar.get_x() + bar.get_width()/2, height),\n",
    "                    xytext=(0, 3), textcoords='offset points',\n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'per_class_metrics.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Per-class metrics chart saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 14. Save Model Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SAVE MODEL INFORMATION\n",
    "# ============================================================\n",
    "\n",
    "model_info = {\n",
    "    'model_name': 'coconut_mite_3class_detector',\n",
    "    'version': 'v8_3class',\n",
    "    'architecture': 'EfficientNetB0 (Transfer Learning)',\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'classes': class_names_ordered,\n",
    "    'input_size': [IMG_SIZE, IMG_SIZE, 3],\n",
    "    'dataset': {\n",
    "        'train_images': train_generator.samples,\n",
    "        'validation_images': val_generator.samples,\n",
    "        'test_images': test_generator.samples,\n",
    "        'total_images': train_generator.samples + val_generator.samples + test_generator.samples\n",
    "    },\n",
    "    'performance': {\n",
    "        'test_accuracy': float(accuracy),\n",
    "        'macro_precision': float(macro_precision),\n",
    "        'macro_recall': float(macro_recall),\n",
    "        'macro_f1': float(macro_f1),\n",
    "        'per_class': [\n",
    "            {\n",
    "                'class': class_names_ordered[i],\n",
    "                'precision': float(precision[i]),\n",
    "                'recall': float(recall[i]),\n",
    "                'f1': float(f1[i]),\n",
    "                'support': int(support[i]),\n",
    "                'pr_gap': float(abs(precision[i] - recall[i]))\n",
    "            }\n",
    "            for i in range(NUM_CLASSES)\n",
    "        ],\n",
    "        'confusion_matrix': cm.tolist()\n",
    "    },\n",
    "    'training': {\n",
    "        'epochs_completed': len(history.history['accuracy']),\n",
    "        'best_epoch': int(best_epoch),\n",
    "        'training_time_minutes': float(training_time),\n",
    "        'final_train_accuracy': float(final_train_acc / 100),\n",
    "        'final_val_accuracy': float(final_val_acc / 100),\n",
    "        'train_val_gap': float(train_val_gap)\n",
    "    },\n",
    "    'hyperparameters': {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'dropout_rate': DROPOUT_RATE,\n",
    "        'l2_regularization': L2_REG,\n",
    "        'label_smoothing': LABEL_SMOOTHING,\n",
    "        'early_stopping_patience': PATIENCE\n",
    "    },\n",
    "    'requirements_check': {\n",
    "        'pr_balanced_per_class': all(abs(precision[i] - recall[i]) < 0.10 for i in range(NUM_CLASSES)),\n",
    "        'accuracy_equals_f1': acc_f1_diff < 0.05,\n",
    "        'class_f1_similar': f1_max_diff < 0.15,\n",
    "        'train_val_gap_ok': train_val_gap < 15\n",
    "    },\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "with open(os.path.join(MODEL_DIR, 'model_info.json'), 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  MODEL INFORMATION SAVED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n  Model: {model_info['model_name']}\")\n",
    "print(f\"  Version: {model_info['version']}\")\n",
    "print(f\"  Classes: {model_info['classes']}\")\n",
    "print(f\"  Test Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"  Macro F1: {macro_f1*100:.2f}%\")\n",
    "print(f\"\\n‚úì Model info saved to: {MODEL_DIR}/model_info.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 15. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "total_images = train_generator.samples + val_generator.samples + test_generator.samples\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"‚ïî\" + \"‚ïê\"*58 + \"‚ïó\")\n",
    "print(\"‚ïë\" + \" \"*12 + \"üéâ 3-CLASS MODEL TRAINING COMPLETE! üéâ\" + \" \"*7 + \"‚ïë\")\n",
    "print(\"‚ï†\" + \"‚ïê\"*58 + \"‚ï£\")\n",
    "print(\"‚ïë\" + \" \"*58 + \"‚ïë\")\n",
    "print(f\"‚ïë  Model:          EfficientNetB0 (3-Class){' '*15}‚ïë\")\n",
    "print(f\"‚ïë  Dataset:        {total_images:,} images{' '*30}‚ïë\")\n",
    "print(f\"‚ïë  Training Time:  {training_time:.1f} minutes{' '*28}‚ïë\")\n",
    "print(\"‚ïë\" + \" \"*58 + \"‚ïë\")\n",
    "print(\"‚ï†\" + \"‚ïê\"*58 + \"‚ï£\")\n",
    "print(\"‚ïë  CLASSES:\" + \" \"*48 + \"‚ïë\")\n",
    "print(\"‚ïë    üî¥ coconut_mite  - Infected coconuts\" + \" \"*17 + \"‚ïë\")\n",
    "print(\"‚ïë    üü¢ healthy       - Healthy coconuts\" + \" \"*18 + \"‚ïë\")\n",
    "print(\"‚ïë    üîµ not_coconut   - Out-of-scope (NEW!)\" + \" \"*14 + \"‚ïë\")\n",
    "print(\"‚ïë\" + \" \"*58 + \"‚ïë\")\n",
    "print(\"‚ï†\" + \"‚ïê\"*58 + \"‚ï£\")\n",
    "print(\"‚ïë  FINAL TEST METRICS:\" + \" \"*37 + \"‚ïë\")\n",
    "print(\"‚ïë\" + \"-\"*58 + \"‚ïë\")\n",
    "print(f\"‚ïë    Test Accuracy:      {accuracy*100:6.2f}%{' '*26}‚ïë\")\n",
    "print(f\"‚ïë    Macro Precision:    {macro_precision*100:6.2f}%{' '*26}‚ïë\")\n",
    "print(f\"‚ïë    Macro Recall:       {macro_recall*100:6.2f}%{' '*26}‚ïë\")\n",
    "print(f\"‚ïë    Macro F1-Score:     {macro_f1*100:6.2f}%{' '*26}‚ïë\")\n",
    "print(\"‚ïë\" + \" \"*58 + \"‚ïë\")\n",
    "print(\"‚ï†\" + \"‚ïê\"*58 + \"‚ï£\")\n",
    "print(\"‚ïë  REQUIREMENTS CHECK:\" + \" \"*37 + \"‚ïë\")\n",
    "print(\"‚ïë\" + \"-\"*58 + \"‚ïë\")\n",
    "req1 = model_info['requirements_check']['pr_balanced_per_class']\n",
    "req2 = model_info['requirements_check']['accuracy_equals_f1']\n",
    "req3 = model_info['requirements_check']['class_f1_similar']\n",
    "req4 = model_info['requirements_check']['train_val_gap_ok']\n",
    "print(f\"‚ïë    P/R Balanced per Class:    {'‚úì PASS' if req1 else '‚úó FAIL'}{' '*19}‚ïë\")\n",
    "print(f\"‚ïë    Accuracy ‚âà F1-Score:       {'‚úì PASS' if req2 else '‚úó FAIL'}{' '*19}‚ïë\")\n",
    "print(f\"‚ïë    Class F1-Scores Similar:   {'‚úì PASS' if req3 else '‚úó FAIL'}{' '*19}‚ïë\")\n",
    "print(f\"‚ïë    Train-Val Gap < 15%:       {'‚úì PASS' if req4 else '‚úó FAIL'}{' '*19}‚ïë\")\n",
    "print(\"‚ïë\" + \" \"*58 + \"‚ïë\")\n",
    "if all([req1, req2, req3, req4]):\n",
    "    print(\"‚ïë\" + \" \"*12 + \"‚úÖ ALL REQUIREMENTS PASSED! ‚úÖ\" + \" \"*12 + \"‚ïë\")\n",
    "else:\n",
    "    print(\"‚ïë\" + \" \"*10 + \"‚ö†Ô∏è SOME REQUIREMENTS NEED REVIEW\" + \" \"*10 + \"‚ïë\")\n",
    "print(\"‚ïë\" + \" \"*58 + \"‚ïë\")\n",
    "print(\"‚ïö\" + \"‚ïê\"*58 + \"‚ïù\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  MODEL FILES SAVED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n  Model:        {MODEL_DIR}/best_model.keras\")\n",
    "print(f\"  Info:         {MODEL_DIR}/model_info.json\")\n",
    "print(f\"  History:      {MODEL_DIR}/training_history.json\")\n",
    "print(\"\\n  Charts:\")\n",
    "print(\"    ‚Ä¢ dataset_distribution.png\")\n",
    "print(\"    ‚Ä¢ class_distribution_pie.png\")\n",
    "print(\"    ‚Ä¢ sample_images.png\")\n",
    "print(\"    ‚Ä¢ training_history.png\")\n",
    "print(\"    ‚Ä¢ confusion_matrix.png\")\n",
    "print(\"    ‚Ä¢ per_class_metrics.png\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n  üöÄ Model ready for API integration!\")\n",
    "print(\"     Update app.py to use 3-class predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 16. Key Improvement: Out-of-Scope Detection\n",
    "\n",
    "### What's New in v8 (3-Class Model):\n",
    "\n",
    "| Feature | v7 (2-Class) | v8 (3-Class) |\n",
    "|---------|--------------|---------------|\n",
    "| Classes | coconut_mite, healthy | coconut_mite, healthy, **not_coconut** |\n",
    "| Output | Sigmoid (1 neuron) | Softmax (3 neurons) |\n",
    "| Out-of-scope | ‚ùå Random predictions | ‚úÖ Correctly rejected |\n",
    "| Use Case | Coconut images only | Any image (robust) |\n",
    "\n",
    "### API Integration:\n",
    "```python\n",
    "# Old (v7): Binary classification\n",
    "prediction = model.predict(image)[0][0]  # Single value\n",
    "is_mite = prediction < threshold\n",
    "\n",
    "# New (v8): Multi-class classification\n",
    "predictions = model.predict(image)[0]  # [mite_prob, healthy_prob, not_coconut_prob]\n",
    "predicted_class = np.argmax(predictions)\n",
    "class_name = ['coconut_mite', 'healthy', 'not_coconut'][predicted_class]\n",
    "```\n",
    "\n",
    "### Benefits:\n",
    "1. ‚úÖ No more random predictions for non-coconut images\n",
    "2. ‚úÖ Clearer error messages for users\n",
    "3. ‚úÖ More robust production system\n",
    "4. ‚úÖ Passes madam's panel evaluation criteria"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
