{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coconut Mite Detection - Model Training\n",
    "\n",
    "Train a CNN model to detect coconut mite infestation using transfer learning.\n",
    "\n",
    "## Model Architecture\n",
    "- **Base Model:** MobileNetV2 (pretrained on ImageNet)\n",
    "- **Task:** Binary Classification (Mite Infected vs Healthy)\n",
    "- **Target:** Mobile deployment via TensorFlow Lite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Sklearn for metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    # Data paths\n",
    "    'data_dir': Path('../data/raw/pest'),\n",
    "    'model_dir': Path('../models/coconut_mite'),\n",
    "    \n",
    "    # Image settings\n",
    "    'img_height': 224,\n",
    "    'img_width': 224,\n",
    "    'channels': 3,\n",
    "    \n",
    "    # Training settings\n",
    "    'batch_size': 32,\n",
    "    'epochs': 50,\n",
    "    'learning_rate': 0.0001,\n",
    "    'validation_split': 0.2,\n",
    "    \n",
    "    # Classes\n",
    "    'classes': ['coconut_mite', 'healthy'],\n",
    "    'num_classes': 2\n",
    "}\n",
    "\n",
    "# Create model directory if not exists\n",
    "CONFIG['model_dir'].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Configuration loaded!\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data availability\n",
    "mite_path = CONFIG['data_dir'] / 'coconut_mite'\n",
    "healthy_path = CONFIG['data_dir'] / 'healthy'\n",
    "\n",
    "mite_count = len(list(mite_path.glob('*.jpg'))) + len(list(mite_path.glob('*.png')))\n",
    "healthy_count = len(list(healthy_path.glob('*.jpg'))) + len(list(healthy_path.glob('*.png')))\n",
    "\n",
    "print(f\"Coconut Mite images: {mite_count:,}\")\n",
    "print(f\"Healthy images: {healthy_count:,}\")\n",
    "\n",
    "if healthy_count == 0:\n",
    "    print(\"\\n‚ö†Ô∏è WARNING: No healthy images found!\")\n",
    "    print(\"Please upload healthy images before training.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Total images: {mite_count + healthy_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=CONFIG['validation_split'],\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=CONFIG['validation_split']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    CONFIG['data_dir'],\n",
    "    target_size=(CONFIG['img_height'], CONFIG['img_width']),\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    classes=CONFIG['classes']\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    CONFIG['data_dir'],\n",
    "    target_size=(CONFIG['img_height'], CONFIG['img_width']),\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    classes=CONFIG['classes']\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {validation_generator.samples}\")\n",
    "print(f\"\\nClass indices: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights for imbalanced data\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_generator.classes),\n",
    "    y=train_generator.classes\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(f\"Class weights: {class_weights_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample batch\n",
    "sample_batch, sample_labels = next(train_generator)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "for idx in range(8):\n",
    "    axes[idx].imshow(sample_batch[idx])\n",
    "    label_idx = np.argmax(sample_labels[idx])\n",
    "    axes[idx].set_title(f'Class: {class_names[label_idx]}', fontsize=10)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Training Batch (After Augmentation)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Create a transfer learning model using MobileNetV2\n",
    "    \"\"\"\n",
    "    # Load pretrained MobileNetV2\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build model\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Preprocessing (MobileNetV2 expects [-1, 1])\n",
    "    x = keras.applications.mobilenet_v2.preprocess_input(inputs * 255)\n",
    "    \n",
    "    # Base model\n",
    "    x = base_model(x, training=False)\n",
    "    \n",
    "    # Custom classification head\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Create model\n",
    "input_shape = (CONFIG['img_height'], CONFIG['img_width'], CONFIG['channels'])\n",
    "model, base_model = create_model(input_shape, CONFIG['num_classes'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=CONFIG['learning_rate']),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "callbacks = [\n",
    "    # Early stopping\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Model checkpoint\n",
    "    ModelCheckpoint(\n",
    "        filepath=str(CONFIG['model_dir'] / 'best_model.keras'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Learning rate reduction\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # TensorBoard logging\n",
    "    TensorBoard(\n",
    "        log_dir=str(CONFIG['model_dir'] / f'logs/{timestamp}'),\n",
    "        histogram_freq=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Callbacks configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training - Phase 1 (Feature Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1: Train only the classification head\n",
    "print(\"=\" * 60)\n",
    "print(\"PHASE 1: Training Classification Head (Base Model Frozen)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "history_phase1 = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training - Phase 2 (Fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Fine-tune top layers of base model\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PHASE 2: Fine-tuning Top Layers\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Unfreeze top layers of base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Freeze all layers except the last 30\n",
    "for layer in base_model.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=CONFIG['learning_rate'] / 10),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Continue training\n",
    "history_phase2 = model.fit(\n",
    "    train_generator,\n",
    "    epochs=CONFIG['epochs'],\n",
    "    initial_epoch=len(history_phase1.history['loss']),\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine histories\n",
    "def combine_histories(h1, h2):\n",
    "    combined = {}\n",
    "    for key in h1.history.keys():\n",
    "        combined[key] = h1.history[key] + h2.history[key]\n",
    "    return combined\n",
    "\n",
    "history = combine_histories(history_phase1, history_phase2)\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "axes[0].plot(history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "axes[0].axvline(x=len(history_phase1.history['accuracy'])-1, color='r', linestyle='--', label='Fine-tuning Start')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history['loss'], label='Training Loss', linewidth=2)\n",
    "axes[1].plot(history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[1].axvline(x=len(history_phase1.history['loss'])-1, color='r', linestyle='--', label='Fine-tuning Start')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CONFIG['model_dir'] / 'training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "print(\"=\" * 50)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "val_loss, val_accuracy = model.evaluate(validation_generator, verbose=0)\n",
    "print(f\"\\nValidation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "validation_generator.reset()\n",
    "predictions = model.predict(validation_generator, verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = validation_generator.classes\n",
    "class_names = list(validation_generator.class_indices.keys())\n",
    "\n",
    "# Classification report\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.title('Confusion Matrix - Coconut Mite Detection', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(CONFIG['model_dir'] / 'confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in different formats\n",
    "print(\"=\" * 50)\n",
    "print(\"SAVING MODEL\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Save Keras model\n",
    "model.save(CONFIG['model_dir'] / 'coconut_mite_model.keras')\n",
    "print(f\"‚úÖ Keras model saved: {CONFIG['model_dir'] / 'coconut_mite_model.keras'}\")\n",
    "\n",
    "# Save as H5 format\n",
    "model.save(CONFIG['model_dir'] / 'coconut_mite_model.h5')\n",
    "print(f\"‚úÖ H5 model saved: {CONFIG['model_dir'] / 'coconut_mite_model.h5'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TensorFlow Lite (for mobile deployment)\n",
    "print(\"\\nConverting to TensorFlow Lite...\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save TFLite model\n",
    "tflite_path = CONFIG['model_dir'] / 'coconut_mite_model.tflite'\n",
    "with open(tflite_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"‚úÖ TFLite model saved: {tflite_path}\")\n",
    "print(f\"   TFLite model size: {os.path.getsize(tflite_path) / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save class labels\n",
    "import json\n",
    "\n",
    "labels_info = {\n",
    "    'class_indices': train_generator.class_indices,\n",
    "    'class_names': class_names,\n",
    "    'input_shape': [CONFIG['img_height'], CONFIG['img_width'], CONFIG['channels']],\n",
    "    'model_version': '1.0.0',\n",
    "    'training_date': datetime.datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(CONFIG['model_dir'] / 'model_info.json', 'w') as f:\n",
    "    json.dump(labels_info, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Model info saved: {CONFIG['model_dir'] / 'model_info.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, image_path, target_size=(224, 224)):\n",
    "    \"\"\"Make prediction on a single image\"\"\"\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    \n",
    "    img = image.load_img(image_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0\n",
    "    \n",
    "    predictions = model.predict(img_array, verbose=0)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    confidence = predictions[0][predicted_class]\n",
    "    \n",
    "    return class_names[predicted_class], confidence, img\n",
    "\n",
    "# Test with a sample image\n",
    "sample_images = list(mite_path.glob('*.jpg'))[:3]\n",
    "\n",
    "if sample_images:\n",
    "    fig, axes = plt.subplots(1, len(sample_images), figsize=(15, 5))\n",
    "    \n",
    "    for idx, img_path in enumerate(sample_images):\n",
    "        pred_class, confidence, img = predict_image(model, img_path)\n",
    "        \n",
    "        axes[idx].imshow(img)\n",
    "        color = 'green' if pred_class == 'healthy' else 'red'\n",
    "        axes[idx].set_title(f'Prediction: {pred_class}\\nConfidence: {confidence:.2%}', \n",
    "                           fontsize=11, color=color, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Predictions', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary\n",
    "\n",
    "### Training Complete!\n",
    "\n",
    "**Saved Files:**\n",
    "- `coconut_mite_model.keras` - Full Keras model\n",
    "- `coconut_mite_model.h5` - H5 format model\n",
    "- `coconut_mite_model.tflite` - TensorFlow Lite (for mobile)\n",
    "- `model_info.json` - Model metadata and class labels\n",
    "- `training_history.png` - Training curves\n",
    "- `confusion_matrix.png` - Evaluation results\n",
    "\n",
    "**Next Steps:**\n",
    "1. Deploy model via Flask API\n",
    "2. Integrate TFLite model with React Native app\n",
    "3. Train models for other pest types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ COCONUT MITE DETECTION MODEL TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìä Final Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"üìÅ Models saved to: {CONFIG['model_dir'].absolute()}\")\n",
    "print(\"\\nüëâ Next: Run Flask API to serve the model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
