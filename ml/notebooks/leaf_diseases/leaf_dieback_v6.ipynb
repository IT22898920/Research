{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Coconut Leaf Dieback Detection Model v6\n",
        "\n",
        "This notebook trains a model to detect **leaf dieback disease** in coconut trees.\n",
        "\n",
        "## Model Configuration\n",
        "- **Architecture:** MobileNetV2 (Transfer Learning)\n",
        "- **Loss Function:** Focal Loss (gamma=2.0) for handling class imbalance\n",
        "- **Training Strategy:** 2-phase training (frozen base â†’ fine-tuning)\n",
        "- **Classes:** 3 (healthy, leaf_die_back, not_cocount)\n",
        "\n",
        "## Goals (Madam's Requirements)\n",
        "- Avoid data leaking and overfitting\n",
        "- Balanced Precision, Recall, F1-score for each class\n",
        "- Similar values across all classes\n",
        "- Accuracy close to macro F1-score\n",
        "- Real outputs, not hardcoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
        "\n",
        "# Set random seeds for reproducibility (IMPORTANT: prevents randomness issues)\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "print(f\"\\nRandom seed set to {SEED} for reproducibility\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paths\n",
        "BASE_DIR = os.path.abspath(os.path.join('..', '..'))\n",
        "RAW_DATASET_DIR = os.path.join(BASE_DIR, 'data', 'raw', 'leaf_dieback_v1')\n",
        "BALANCED_DATASET_DIR = os.path.join(BASE_DIR, 'data', 'processed', 'leaf_dieback_balanced')\n",
        "MODEL_DIR = os.path.join(BASE_DIR, 'models', 'leaf_dieback_v6')\n",
        "\n",
        "# Model parameters\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "PHASE1_EPOCHS = 25  # Frozen base\n",
        "PHASE2_EPOCHS = 20  # Fine-tuning\n",
        "LEARNING_RATE_PHASE1 = 1e-3\n",
        "LEARNING_RATE_PHASE2 = 1e-5\n",
        "\n",
        "# Classes (must match folder names)\n",
        "CLASS_NAMES = ['healthy', 'leaf_die_back', 'not_cocount']\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(BALANCED_DATASET_DIR, exist_ok=True)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"CONFIGURATION\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Base Directory:      {BASE_DIR}\")\n",
        "print(f\"Raw Dataset:         {RAW_DATASET_DIR}\")\n",
        "print(f\"Balanced Dataset:    {BALANCED_DATASET_DIR}\")\n",
        "print(f\"Model Directory:     {MODEL_DIR}\")\n",
        "print(f\"Image Size:          {IMG_SIZE}x{IMG_SIZE}\")\n",
        "print(f\"Batch Size:          {BATCH_SIZE}\")\n",
        "print(f\"Classes:             {CLASS_NAMES}\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Exploratory Data Analysis (EDA)\n",
        "\n",
        "First, let's examine the raw dataset to understand the class distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count images in each split and class (BEFORE balancing)\n",
        "raw_data_summary = {}\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"RAW DATASET SUMMARY (BEFORE BALANCING)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for split in ['train', 'val', 'test']:\n",
        "    split_path = os.path.join(RAW_DATASET_DIR, split)\n",
        "    print(f\"\\n{split.upper()}:\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    split_total = 0\n",
        "    for cls in CLASS_NAMES:\n",
        "        cls_path = os.path.join(split_path, cls)\n",
        "        if os.path.exists(cls_path):\n",
        "            count = len([f for f in os.listdir(cls_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "        else:\n",
        "            count = 0\n",
        "        split_total += count\n",
        "        print(f\"  {cls:<20} {count:>6} images\")\n",
        "        \n",
        "        if split not in raw_data_summary:\n",
        "            raw_data_summary[split] = {}\n",
        "        raw_data_summary[split][cls] = count\n",
        "    \n",
        "    print(f\"  {'TOTAL':<20} {split_total:>6} images\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "# Identify imbalance\n",
        "print(\"\\nIMBALANCE DETECTED:\")\n",
        "for split in ['val', 'test']:\n",
        "    counts = [raw_data_summary[split][cls] for cls in CLASS_NAMES]\n",
        "    min_count = min(counts)\n",
        "    max_count = max(counts)\n",
        "    ratio = max_count / min_count if min_count > 0 else float('inf')\n",
        "    print(f\"  {split.upper()}: min={min_count}, max={max_count}, ratio={ratio:.2f}x\")\n",
        "    if ratio > 1.5:\n",
        "        print(f\"    --> Need to balance {split} set!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Balance Validation and Test Sets\n",
        "\n",
        "The validation and test sets are imbalanced. We'll balance them by:\n",
        "1. Moving images from training to val/test for underrepresented classes\n",
        "2. Creating a properly balanced dataset\n",
        "\n",
        "**IMPORTANT:** This prevents biased evaluation and ensures fair metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def balance_dataset(raw_dir, balanced_dir, class_names, target_val_test=90):\n",
        "    \"\"\"\n",
        "    Balance the dataset by redistributing images.\n",
        "    \n",
        "    Strategy:\n",
        "    - Target ~90 images per class in val and test\n",
        "    - Move images from train to val/test for underrepresented classes\n",
        "    - This ensures balanced evaluation metrics\n",
        "    \"\"\"\n",
        "    \n",
        "    print(\"=\" * 70)\n",
        "    print(\"BALANCING DATASET\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    # Create directory structure\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        for cls in class_names:\n",
        "            os.makedirs(os.path.join(balanced_dir, split, cls), exist_ok=True)\n",
        "    \n",
        "    # Check if already balanced\n",
        "    already_done = True\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        for cls in class_names:\n",
        "            balanced_path = os.path.join(balanced_dir, split, cls)\n",
        "            if not os.path.exists(balanced_path) or len(os.listdir(balanced_path)) == 0:\n",
        "                already_done = False\n",
        "                break\n",
        "    \n",
        "    if already_done:\n",
        "        print(\"Dataset already balanced. Skipping...\")\n",
        "        return\n",
        "    \n",
        "    # Step 1: Copy all raw data to balanced directory first\n",
        "    print(\"\\nStep 1: Copying raw data...\")\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        for cls in class_names:\n",
        "            src_dir = os.path.join(raw_dir, split, cls)\n",
        "            dst_dir = os.path.join(balanced_dir, split, cls)\n",
        "            \n",
        "            if os.path.exists(src_dir):\n",
        "                files = [f for f in os.listdir(src_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "                for f in files:\n",
        "                    src_file = os.path.join(src_dir, f)\n",
        "                    dst_file = os.path.join(dst_dir, f)\n",
        "                    if not os.path.exists(dst_file):\n",
        "                        shutil.copy2(src_file, dst_file)\n",
        "                print(f\"  Copied {len(files)} files to {split}/{cls}\")\n",
        "    \n",
        "    # Step 2: Balance val and test sets\n",
        "    print(\"\\nStep 2: Balancing val and test sets...\")\n",
        "    \n",
        "    for split in ['val', 'test']:\n",
        "        for cls in class_names:\n",
        "            split_cls_dir = os.path.join(balanced_dir, split, cls)\n",
        "            current_count = len([f for f in os.listdir(split_cls_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "            \n",
        "            if current_count < target_val_test:\n",
        "                # Need to add more images from training\n",
        "                needed = target_val_test - current_count\n",
        "                train_cls_dir = os.path.join(balanced_dir, 'train', cls)\n",
        "                \n",
        "                train_files = [f for f in os.listdir(train_cls_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "                random.shuffle(train_files)\n",
        "                \n",
        "                # Move files from train to val/test\n",
        "                moved = 0\n",
        "                for f in train_files[:needed]:\n",
        "                    src_file = os.path.join(train_cls_dir, f)\n",
        "                    # Rename to avoid conflicts\n",
        "                    new_name = f\"moved_from_train_{f}\"\n",
        "                    dst_file = os.path.join(split_cls_dir, new_name)\n",
        "                    if os.path.exists(src_file):\n",
        "                        shutil.move(src_file, dst_file)\n",
        "                        moved += 1\n",
        "                \n",
        "                print(f\"  Moved {moved} images from train to {split}/{cls}\")\n",
        "    \n",
        "    print(\"\\nDataset balancing complete!\")\n",
        "    return True\n",
        "\n",
        "# Balance the dataset\n",
        "balance_dataset(RAW_DATASET_DIR, BALANCED_DATASET_DIR, CLASS_NAMES, target_val_test=90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count images AFTER balancing\n",
        "data_summary = {}\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"BALANCED DATASET SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "total_images = 0\n",
        "for split in ['train', 'val', 'test']:\n",
        "    split_path = os.path.join(BALANCED_DATASET_DIR, split)\n",
        "    print(f\"\\n{split.upper()}:\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    split_total = 0\n",
        "    for cls in CLASS_NAMES:\n",
        "        cls_path = os.path.join(split_path, cls)\n",
        "        if os.path.exists(cls_path):\n",
        "            count = len([f for f in os.listdir(cls_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "        else:\n",
        "            count = 0\n",
        "        split_total += count\n",
        "        print(f\"  {cls:<20} {count:>6} images\")\n",
        "        \n",
        "        if split not in data_summary:\n",
        "            data_summary[split] = {}\n",
        "        data_summary[split][cls] = count\n",
        "    \n",
        "    print(f\"  {'TOTAL':<20} {split_total:>6} images\")\n",
        "    total_images += split_total\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(f\"TOTAL BALANCED IMAGES: {total_images}\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize class distribution (AFTER balancing)\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "fig.suptitle('Class Distribution Across Splits (BALANCED)', fontsize=14, fontweight='bold')\n",
        "\n",
        "colors = ['#2ecc71', '#e74c3c', '#3498db']  # green, red, blue\n",
        "\n",
        "for idx, split in enumerate(['train', 'val', 'test']):\n",
        "    counts = [data_summary[split][cls] for cls in CLASS_NAMES]\n",
        "    bars = axes[idx].bar(CLASS_NAMES, counts, color=colors)\n",
        "    axes[idx].set_title(f'{split.upper()} Split', fontweight='bold')\n",
        "    axes[idx].set_ylabel('Number of Images')\n",
        "    axes[idx].set_xlabel('Class')\n",
        "    axes[idx].tick_params(axis='x', rotation=15)\n",
        "    \n",
        "    # Add count labels\n",
        "    for bar, count in zip(bars, counts):\n",
        "        axes[idx].text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n",
        "                       str(count), ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(MODEL_DIR, 'class_distribution_balanced.png'), dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Check balance ratio\n",
        "print(\"\\nBalance Check:\")\n",
        "for split in ['val', 'test']:\n",
        "    counts = [data_summary[split][cls] for cls in CLASS_NAMES]\n",
        "    ratio = max(counts) / min(counts) if min(counts) > 0 else float('inf')\n",
        "    status = \"Balanced!\" if ratio < 1.2 else \"Needs attention\"\n",
        "    print(f\"  {split.upper()}: ratio={ratio:.2f}x - {status}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualize Sample Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Show sample images from each class\n",
        "fig, axes = plt.subplots(3, 5, figsize=(15, 10))\n",
        "fig.suptitle('Sample Images from Balanced Training Set', fontsize=14, fontweight='bold')\n",
        "\n",
        "class_colors = {'healthy': 'green', 'leaf_die_back': 'red', 'not_cocount': 'blue'}\n",
        "\n",
        "for row, cls in enumerate(CLASS_NAMES):\n",
        "    cls_dir = os.path.join(BALANCED_DATASET_DIR, 'train', cls)\n",
        "    images_list = [f for f in os.listdir(cls_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    \n",
        "    # Get 5 random images\n",
        "    sample_imgs = random.sample(images_list, min(5, len(images_list)))\n",
        "    \n",
        "    for col, img_name in enumerate(sample_imgs):\n",
        "        img_path = os.path.join(cls_dir, img_name)\n",
        "        img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "        \n",
        "        axes[row, col].imshow(img)\n",
        "        axes[row, col].axis('off')\n",
        "    \n",
        "    # Add class label\n",
        "    axes[row, 0].text(-0.3, 0.5, cls.replace('_', '\\n').upper(), \n",
        "                      transform=axes[row, 0].transAxes,\n",
        "                      fontsize=10, fontweight='bold', va='center', ha='right',\n",
        "                      color=class_colors[cls])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(MODEL_DIR, 'sample_images.png'), dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Data Generators with Augmentation\n",
        "\n",
        "**IMPORTANT - Preventing Data Leakage:**\n",
        "- Augmentation is ONLY applied to training data\n",
        "- Validation and test use raw images with only rescaling\n",
        "- No data from val/test leaks into training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training data generator with augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    zoom_range=0.2,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    shear_range=0.15,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Validation and test generators - NO augmentation\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "print(\"Data Augmentation (Training Only):\")\n",
        "print(\"-\" * 50)\n",
        "print(\"  - Rotation: +/-30 degrees\")\n",
        "print(\"  - Width/Height Shift: +/-20%\")\n",
        "print(\"  - Horizontal & Vertical Flip\")\n",
        "print(\"  - Zoom: +/-20%\")\n",
        "print(\"  - Brightness: 80-120%\")\n",
        "print(\"  - Shear: +/-15%\")\n",
        "print(\"\\nNo augmentation on validation/test data (prevents data leakage)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create generators from BALANCED dataset\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(BALANCED_DATASET_DIR, 'train'),\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    classes=CLASS_NAMES,\n",
        "    shuffle=True,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    os.path.join(BALANCED_DATASET_DIR, 'val'),\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    classes=CLASS_NAMES,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    os.path.join(BALANCED_DATASET_DIR, 'test'),\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    classes=CLASS_NAMES,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"DATA GENERATORS CREATED (FROM BALANCED DATASET)\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Training samples:   {train_generator.samples}\")\n",
        "print(f\"Validation samples: {val_generator.samples}\")\n",
        "print(f\"Test samples:       {test_generator.samples}\")\n",
        "print(f\"\\nClass indices: {train_generator.class_indices}\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualize Augmented Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show augmented images\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "fig.suptitle('Data Augmentation Examples (Same Image)', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Get a sample image\n",
        "sample_cls = 'leaf_die_back'\n",
        "cls_dir = os.path.join(BALANCED_DATASET_DIR, 'train', sample_cls)\n",
        "sample_img_name = random.choice([f for f in os.listdir(cls_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "sample_img_path = os.path.join(cls_dir, sample_img_name)\n",
        "\n",
        "# Load image\n",
        "img = image.load_img(sample_img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Show original\n",
        "axes[0, 0].imshow(img)\n",
        "axes[0, 0].set_title('Original', fontweight='bold')\n",
        "axes[0, 0].axis('off')\n",
        "\n",
        "# Generate augmented versions\n",
        "aug_gen = train_datagen.flow(img_array, batch_size=1, seed=42)\n",
        "for i in range(9):\n",
        "    row, col = (i + 1) // 5, (i + 1) % 5\n",
        "    augmented = next(aug_gen)[0]\n",
        "    axes[row, col].imshow(augmented)\n",
        "    axes[row, col].set_title(f'Augmented {i+1}')\n",
        "    axes[row, col].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(MODEL_DIR, 'augmentation_examples.png'), dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Define Focal Loss\n",
        "\n",
        "Focal Loss helps with class imbalance by focusing on hard-to-classify examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def focal_loss(gamma=2.0, alpha=0.25):\n",
        "    \"\"\"\n",
        "    Focal Loss for handling class imbalance.\n",
        "    \n",
        "    Args:\n",
        "        gamma: Focusing parameter (higher = more focus on hard examples)\n",
        "        alpha: Class balancing parameter\n",
        "    \"\"\"\n",
        "    def focal_loss_fn(y_true, y_pred):\n",
        "        epsilon = tf.keras.backend.epsilon()\n",
        "        y_pred = tf.keras.backend.clip(y_pred, epsilon, 1.0 - epsilon)\n",
        "        \n",
        "        # Cross entropy\n",
        "        cross_entropy = -y_true * tf.keras.backend.log(y_pred)\n",
        "        \n",
        "        # Focal weight: (1 - p)^gamma\n",
        "        focal_weight = tf.keras.backend.pow(1.0 - y_pred, gamma)\n",
        "        \n",
        "        # Focal loss\n",
        "        focal_loss = alpha * focal_weight * cross_entropy\n",
        "        \n",
        "        return tf.keras.backend.sum(focal_loss, axis=-1)\n",
        "    \n",
        "    return focal_loss_fn\n",
        "\n",
        "print(\"Focal Loss function defined!\")\n",
        "print(f\"  Gamma: 2.0 (focus on hard examples)\")\n",
        "print(f\"  Alpha: 0.25 (class balancing)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Build Model with Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model(num_classes):\n",
        "    \"\"\"\n",
        "    Build MobileNetV2 model with transfer learning.\n",
        "    \"\"\"\n",
        "    # Load pre-trained MobileNetV2\n",
        "    base_model = MobileNetV2(\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    \n",
        "    # Freeze base model initially\n",
        "    base_model.trainable = False\n",
        "    \n",
        "    # Build classification head with regularization\n",
        "    inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.4)(x)  # Dropout for regularization\n",
        "    x = layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    \n",
        "    model = keras.Model(inputs, outputs)\n",
        "    \n",
        "    return model, base_model\n",
        "\n",
        "# Build model\n",
        "model, base_model = build_model(len(CLASS_NAMES))\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"MODEL ARCHITECTURE\")\n",
        "print(\"=\" * 70)\n",
        "model.summary()\n",
        "\n",
        "print(f\"\\nBase model layers: {len(base_model.layers)}\")\n",
        "print(f\"Trainable parameters: {sum([np.prod(w.shape) for w in model.trainable_weights]):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Phase 1: Training with Frozen Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE_PHASE1),\n",
        "    loss=focal_loss(gamma=2.0, alpha=0.25),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "checkpoint_phase1 = ModelCheckpoint(\n",
        "    os.path.join(MODEL_DIR, 'phase1_best.keras'),\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stop_phase1 = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr_phase1 = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"PHASE 1: TRAINING WITH FROZEN BASE MODEL\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Learning Rate:      {LEARNING_RATE_PHASE1}\")\n",
        "print(f\"Max Epochs:         {PHASE1_EPOCHS}\")\n",
        "print(f\"Base Model Frozen:  {not base_model.trainable}\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Phase 1\n",
        "start_time = time.time()\n",
        "\n",
        "history_phase1 = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=PHASE1_EPOCHS,\n",
        "    callbacks=[checkpoint_phase1, early_stop_phase1, reduce_lr_phase1],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "phase1_time = (time.time() - start_time) / 60\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"PHASE 1 COMPLETE\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Training Time: {phase1_time:.1f} minutes\")\n",
        "print(f\"Epochs Run: {len(history_phase1.history['accuracy'])}\")\n",
        "print(f\"Best Val Accuracy: {max(history_phase1.history['val_accuracy'])*100:.2f}%\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Phase 2: Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unfreeze base model for fine-tuning\n",
        "base_model.trainable = True\n",
        "\n",
        "# Only fine-tune last 30 layers\n",
        "fine_tune_at = len(base_model.layers) - 30\n",
        "\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "print(f\"Total base model layers: {len(base_model.layers)}\")\n",
        "print(f\"Fine-tuning from layer: {fine_tune_at}\")\n",
        "print(f\"Layers being fine-tuned: {len(base_model.layers) - fine_tune_at}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Recompile with lower learning rate\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE_PHASE2),\n",
        "    loss=focal_loss(gamma=2.0, alpha=0.25),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks for Phase 2\n",
        "checkpoint_phase2 = ModelCheckpoint(\n",
        "    os.path.join(MODEL_DIR, 'best_model.keras'),\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stop_phase2 = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr_phase2 = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    min_lr=1e-8,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"PHASE 2: FINE-TUNING\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Learning Rate:      {LEARNING_RATE_PHASE2}\")\n",
        "print(f\"Max Epochs:         {PHASE2_EPOCHS}\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Phase 2\n",
        "start_time = time.time()\n",
        "\n",
        "history_phase2 = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=PHASE2_EPOCHS,\n",
        "    callbacks=[checkpoint_phase2, early_stop_phase2, reduce_lr_phase2],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "phase2_time = (time.time() - start_time) / 60\n",
        "total_time = phase1_time + phase2_time\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"PHASE 2 COMPLETE\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Phase 2 Time: {phase2_time:.1f} minutes\")\n",
        "print(f\"Total Training Time: {total_time:.1f} minutes\")\n",
        "print(f\"Best Val Accuracy: {max(history_phase2.history['val_accuracy'])*100:.2f}%\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Training History Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine histories\n",
        "history_combined = {\n",
        "    'accuracy': history_phase1.history['accuracy'] + history_phase2.history['accuracy'],\n",
        "    'val_accuracy': history_phase1.history['val_accuracy'] + history_phase2.history['val_accuracy'],\n",
        "    'loss': history_phase1.history['loss'] + history_phase2.history['loss'],\n",
        "    'val_loss': history_phase1.history['val_loss'] + history_phase2.history['val_loss']\n",
        "}\n",
        "\n",
        "phase1_epochs = len(history_phase1.history['accuracy'])\n",
        "\n",
        "# Plot training history\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "fig.suptitle('Training History - Leaf Dieback Model v6', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Accuracy plot\n",
        "axes[0].plot(history_combined['accuracy'], label='Train Accuracy', linewidth=2, color='#3498db')\n",
        "axes[0].plot(history_combined['val_accuracy'], label='Val Accuracy', linewidth=2, color='#e74c3c')\n",
        "axes[0].axvline(x=phase1_epochs-1, color='gray', linestyle='--', label='Fine-tuning starts', alpha=0.7)\n",
        "axes[0].set_title('Model Accuracy', fontweight='bold')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].legend(loc='lower right')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].set_ylim([0, 1.05])\n",
        "\n",
        "# Loss plot\n",
        "axes[1].plot(history_combined['loss'], label='Train Loss', linewidth=2, color='#3498db')\n",
        "axes[1].plot(history_combined['val_loss'], label='Val Loss', linewidth=2, color='#e74c3c')\n",
        "axes[1].axvline(x=phase1_epochs-1, color='gray', linestyle='--', label='Fine-tuning starts', alpha=0.7)\n",
        "axes[1].set_title('Model Loss', fontweight='bold')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Loss')\n",
        "axes[1].legend(loc='upper right')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(MODEL_DIR, 'training_history.png'), dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for overfitting\n",
        "final_train_acc = history_combined['accuracy'][-1]\n",
        "final_val_acc = history_combined['val_accuracy'][-1]\n",
        "acc_gap = final_train_acc - final_val_acc\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"OVERFITTING CHECK\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Final Train Accuracy: {final_train_acc*100:.2f}%\")\n",
        "print(f\"Final Val Accuracy:   {final_val_acc*100:.2f}%\")\n",
        "print(f\"Accuracy Gap:         {acc_gap*100:.2f}%\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "if acc_gap < 0.05:\n",
        "    print(\"No significant overfitting!\")\n",
        "elif acc_gap < 0.10:\n",
        "    print(\"Minor overfitting - acceptable\")\n",
        "else:\n",
        "    print(\"Overfitting detected - consider more regularization\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Load Best Model and Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model\n",
        "best_model = keras.models.load_model(\n",
        "    os.path.join(MODEL_DIR, 'best_model.keras'),\n",
        "    custom_objects={'focal_loss_fn': focal_loss(gamma=2.0, alpha=0.25)}\n",
        ")\n",
        "\n",
        "print(\"Best model loaded from: best_model.keras\")\n",
        "\n",
        "# Make predictions on test set\n",
        "test_generator.reset()\n",
        "print(\"\\nMaking predictions on test set...\")\n",
        "predictions = best_model.predict(test_generator, verbose=1)\n",
        "\n",
        "# Get true labels and predicted labels\n",
        "y_true = test_generator.classes\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "y_pred_proba = np.max(predictions, axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "test_accuracy = np.mean(y_true == y_pred)\n",
        "print(f\"\\n\" + \"=\" * 70)\n",
        "print(f\"TEST ACCURACY: {test_accuracy*100:.2f}%\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Detailed Class-wise Metrics (Madam's Requirements)\n",
        "\n",
        "Checking:\n",
        "- Precision, Recall, F1-score for each class\n",
        "- P, R, F1 should be close to each other\n",
        "- Similar values across all classes\n",
        "- Accuracy close to macro F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate per-class metrics\n",
        "precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
        "macro_precision = np.mean(precision)\n",
        "macro_recall = np.mean(recall)\n",
        "macro_f1 = np.mean(f1)\n",
        "\n",
        "print(\"=\" * 85)\n",
        "print(\"DETAILED CLASS-WISE METRICS\")\n",
        "print(\"=\" * 85)\n",
        "print(f\"\\n{'Class':<20} {'Precision':>12} {'Recall':>12} {'F1-Score':>12} {'Support':>10}\")\n",
        "print(\"-\" * 85)\n",
        "\n",
        "for i, cls in enumerate(CLASS_NAMES):\n",
        "    print(f\"{cls:<20} {precision[i]*100:>11.2f}% {recall[i]*100:>11.2f}% {f1[i]*100:>11.2f}% {support[i]:>10}\")\n",
        "\n",
        "print(\"-\" * 85)\n",
        "print(f\"{'MACRO AVERAGE':<20} {macro_precision*100:>11.2f}% {macro_recall*100:>11.2f}% {macro_f1*100:>11.2f}%\")\n",
        "print(\"=\" * 85)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize class-wise metrics\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "x = np.arange(len(CLASS_NAMES))\n",
        "width = 0.25\n",
        "\n",
        "bars1 = ax.bar(x - width, precision * 100, width, label='Precision', color='#3498db')\n",
        "bars2 = ax.bar(x, recall * 100, width, label='Recall', color='#2ecc71')\n",
        "bars3 = ax.bar(x + width, f1 * 100, width, label='F1-Score', color='#e74c3c')\n",
        "\n",
        "ax.set_xlabel('Class', fontweight='bold')\n",
        "ax.set_ylabel('Score (%)', fontweight='bold')\n",
        "ax.set_title('Class-wise Precision, Recall, and F1-Score', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels([c.replace('_', '\\n') for c in CLASS_NAMES])\n",
        "ax.legend(loc='lower right')\n",
        "ax.set_ylim([0, 110])\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add value labels\n",
        "for bars in [bars1, bars2, bars3]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.annotate(f'{height:.1f}%',\n",
        "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                    xytext=(0, 3), textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(MODEL_DIR, 'class_metrics.png'), dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check metric balance (Madam's requirements)\n",
        "print(\"=\" * 85)\n",
        "print(\"METRIC BALANCE CHECK (Madam's Requirements)\")\n",
        "print(\"=\" * 85)\n",
        "\n",
        "for i, cls in enumerate(CLASS_NAMES):\n",
        "    p, r, f = precision[i], recall[i], f1[i]\n",
        "    max_diff = max(abs(p - r), abs(p - f), abs(r - f))\n",
        "    \n",
        "    print(f\"\\n{cls.upper()}:\")\n",
        "    print(f\"  Precision: {p*100:.2f}%\")\n",
        "    print(f\"  Recall:    {r*100:.2f}%\")\n",
        "    print(f\"  F1-Score:  {f*100:.2f}%\")\n",
        "    print(f\"  Max difference: {max_diff*100:.2f}%\")\n",
        "    \n",
        "    if max_diff < 0.05:\n",
        "        print(f\"  --> Well balanced!\")\n",
        "    elif max_diff < 0.10:\n",
        "        print(f\"  --> Acceptable balance\")\n",
        "    else:\n",
        "        print(f\"  --> Needs attention\")\n",
        "\n",
        "# Cross-class balance\n",
        "print(\"\\n\" + \"-\" * 85)\n",
        "print(\"CROSS-CLASS BALANCE:\")\n",
        "f1_range = max(f1) - min(f1)\n",
        "print(f\"F1-Score range: {f1_range*100:.2f}%\")\n",
        "if f1_range < 0.10:\n",
        "    print(\"Similar performance across all classes!\")\n",
        "else:\n",
        "    print(\"Some variation across classes\")\n",
        "print(\"=\" * 85)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check accuracy vs F1 alignment\n",
        "acc_f1_diff = abs(test_accuracy - macro_f1)\n",
        "\n",
        "print(\"=\" * 85)\n",
        "print(\"ACCURACY vs F1-SCORE ALIGNMENT\")\n",
        "print(\"=\" * 85)\n",
        "print(f\"\\nTest Accuracy:    {test_accuracy*100:.2f}%\")\n",
        "print(f\"Macro F1-Score:   {macro_f1*100:.2f}%\")\n",
        "print(f\"Difference:       {acc_f1_diff*100:.2f}%\")\n",
        "print(\"-\" * 85)\n",
        "\n",
        "if acc_f1_diff < 0.02:\n",
        "    print(\"Excellent! Accuracy and F1 are very close (< 2%)\")\n",
        "elif acc_f1_diff < 0.05:\n",
        "    print(\"Good! Accuracy and F1 are reasonably close (< 5%)\")\n",
        "else:\n",
        "    print(\"Moderate difference - may indicate class imbalance\")\n",
        "print(\"=\" * 85)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot confusion matrices\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "fig.suptitle('Confusion Matrix - Leaf Dieback Model v6', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Counts\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES, ax=axes[0],\n",
        "            cbar_kws={'label': 'Count'})\n",
        "axes[0].set_title('Confusion Matrix (Counts)', fontsize=12, fontweight='bold')\n",
        "axes[0].set_xlabel('Predicted Label')\n",
        "axes[0].set_ylabel('True Label')\n",
        "\n",
        "# Percentages\n",
        "cm_pct = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
        "sns.heatmap(cm_pct, annot=True, fmt='.1f', cmap='RdYlGn',\n",
        "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES, ax=axes[1],\n",
        "            cbar_kws={'label': 'Percentage (%)'})\n",
        "axes[1].set_title('Confusion Matrix (Row %)', fontsize=12, fontweight='bold')\n",
        "axes[1].set_xlabel('Predicted Label')\n",
        "axes[1].set_ylabel('True Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(MODEL_DIR, 'confusion_matrix.png'), dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print confusion matrix details\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CONFUSION MATRIX ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for i, true_cls in enumerate(CLASS_NAMES):\n",
        "    print(f\"\\n{true_cls.upper()} (True):\")\n",
        "    for j, pred_cls in enumerate(CLASS_NAMES):\n",
        "        count = cm[i, j]\n",
        "        pct = cm_pct[i, j]\n",
        "        if i == j:\n",
        "            print(f\"  Correctly classified as {pred_cls}: {count} ({pct:.1f}%)\")\n",
        "        elif count > 0:\n",
        "            print(f\"  Misclassified as {pred_cls}: {count} ({pct:.1f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 16. Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print sklearn classification report\n",
        "print(\"\\n\" + \"=\" * 85)\n",
        "print(\"SKLEARN CLASSIFICATION REPORT\")\n",
        "print(\"=\" * 85)\n",
        "print(classification_report(y_true, y_pred, target_names=CLASS_NAMES, digits=4))\n",
        "print(\"=\" * 85)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 17. Sample Predictions Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get filenames\n",
        "filenames = test_generator.filenames\n",
        "\n",
        "# Find correct and wrong predictions\n",
        "correct_idx = [i for i in range(len(y_true)) if y_true[i] == y_pred[i]]\n",
        "wrong_idx = [i for i in range(len(y_true)) if y_true[i] != y_pred[i]]\n",
        "\n",
        "print(f\"Total test images: {len(y_true)}\")\n",
        "print(f\"Correct predictions: {len(correct_idx)} ({len(correct_idx)/len(y_true)*100:.1f}%)\")\n",
        "print(f\"Wrong predictions: {len(wrong_idx)} ({len(wrong_idx)/len(y_true)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot correct predictions\n",
        "n_samples = min(10, len(correct_idx))\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 7))\n",
        "fig.suptitle('CORRECT Predictions (Sample)', fontsize=14, fontweight='bold', color='green')\n",
        "\n",
        "sample_correct = random.sample(correct_idx, n_samples)\n",
        "for idx, i in enumerate(sample_correct):\n",
        "    row, col = idx // 5, idx % 5\n",
        "    img_path = os.path.join(BALANCED_DATASET_DIR, 'test', filenames[i])\n",
        "    img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "    \n",
        "    axes[row, col].imshow(img)\n",
        "    axes[row, col].axis('off')\n",
        "    pred_label = CLASS_NAMES[y_pred[i]]\n",
        "    confidence = predictions[i][y_pred[i]] * 100\n",
        "    axes[row, col].set_title(f'{pred_label}\\n({confidence:.1f}%)', fontsize=9, color='green')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(MODEL_DIR, 'correct_predictions.png'), dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot wrong predictions (if any)\n",
        "if len(wrong_idx) > 0:\n",
        "    n_wrong = min(10, len(wrong_idx))\n",
        "    rows = (n_wrong + 4) // 5\n",
        "    fig, axes = plt.subplots(rows, 5, figsize=(15, 3.5 * rows))\n",
        "    fig.suptitle(f'WRONG Predictions ({len(wrong_idx)} total)', fontsize=14, fontweight='bold', color='red')\n",
        "    \n",
        "    if rows == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    \n",
        "    for idx, i in enumerate(wrong_idx[:n_wrong]):\n",
        "        row, col = idx // 5, idx % 5\n",
        "        img_path = os.path.join(BALANCED_DATASET_DIR, 'test', filenames[i])\n",
        "        img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "        \n",
        "        axes[row, col].imshow(img)\n",
        "        axes[row, col].axis('off')\n",
        "        true_label = CLASS_NAMES[y_true[i]]\n",
        "        pred_label = CLASS_NAMES[y_pred[i]]\n",
        "        confidence = predictions[i][y_pred[i]] * 100\n",
        "        axes[row, col].set_title(f'True: {true_label}\\nPred: {pred_label} ({confidence:.1f}%)', \n",
        "                                fontsize=9, color='red')\n",
        "    \n",
        "    # Hide empty subplots\n",
        "    for idx in range(n_wrong, rows * 5):\n",
        "        row, col = idx // 5, idx % 5\n",
        "        axes[row, col].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(MODEL_DIR, 'wrong_predictions.png'), dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"\\nPerfect! No wrong predictions!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 18. Confidence Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze confidence distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "fig.suptitle('Prediction Confidence Analysis', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Correct vs wrong\n",
        "correct_conf = [y_pred_proba[i] for i in correct_idx]\n",
        "wrong_conf = [y_pred_proba[i] for i in wrong_idx] if wrong_idx else []\n",
        "\n",
        "axes[0].hist(correct_conf, bins=20, alpha=0.7, label=f'Correct (n={len(correct_conf)})', color='green')\n",
        "if wrong_conf:\n",
        "    axes[0].hist(wrong_conf, bins=20, alpha=0.7, label=f'Wrong (n={len(wrong_conf)})', color='red')\n",
        "axes[0].set_xlabel('Confidence')\n",
        "axes[0].set_ylabel('Count')\n",
        "axes[0].set_title('Confidence: Correct vs Wrong', fontweight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# By class\n",
        "for i, cls in enumerate(CLASS_NAMES):\n",
        "    cls_conf = [y_pred_proba[j] for j in range(len(y_pred)) if y_pred[j] == i]\n",
        "    axes[1].hist(cls_conf, bins=15, alpha=0.5, label=cls)\n",
        "\n",
        "axes[1].set_xlabel('Confidence')\n",
        "axes[1].set_ylabel('Count')\n",
        "axes[1].set_title('Confidence by Predicted Class', fontweight='bold')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(MODEL_DIR, 'confidence_analysis.png'), dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nConfidence Statistics:\")\n",
        "print(f\"  Correct: Mean={np.mean(correct_conf)*100:.1f}%, Min={np.min(correct_conf)*100:.1f}%\")\n",
        "if wrong_conf:\n",
        "    print(f\"  Wrong: Mean={np.mean(wrong_conf)*100:.1f}%, Max={np.max(wrong_conf)*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 19. Save Model Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create model info\n",
        "model_info = {\n",
        "    'model_name': 'leaf_dieback_v6',\n",
        "    'model_type': 'disease_detection',\n",
        "    'architecture': 'MobileNetV2',\n",
        "    'classes': CLASS_NAMES,\n",
        "    'num_classes': len(CLASS_NAMES),\n",
        "    'input_shape': [IMG_SIZE, IMG_SIZE, 3],\n",
        "    'training': {\n",
        "        'phase1_epochs': len(history_phase1.history['accuracy']),\n",
        "        'phase2_epochs': len(history_phase2.history['accuracy']),\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'learning_rate_phase1': LEARNING_RATE_PHASE1,\n",
        "        'learning_rate_phase2': LEARNING_RATE_PHASE2,\n",
        "        'loss_function': 'Focal Loss (gamma=2.0, alpha=0.25)',\n",
        "        'training_time_minutes': round(total_time, 1),\n",
        "        'final_train_accuracy': float(final_train_acc),\n",
        "        'final_val_accuracy': float(final_val_acc),\n",
        "        'overfitting_gap': float(acc_gap)\n",
        "    },\n",
        "    'data': {\n",
        "        'train_samples': train_generator.samples,\n",
        "        'val_samples': val_generator.samples,\n",
        "        'test_samples': test_generator.samples,\n",
        "        'balanced': True\n",
        "    },\n",
        "    'test_performance': {\n",
        "        'accuracy': float(test_accuracy),\n",
        "        'macro_precision': float(macro_precision),\n",
        "        'macro_recall': float(macro_recall),\n",
        "        'macro_f1': float(macro_f1),\n",
        "        'accuracy_f1_difference': float(acc_f1_diff),\n",
        "        'per_class': {}\n",
        "    }\n",
        "}\n",
        "\n",
        "# Add per-class metrics\n",
        "for i, cls in enumerate(CLASS_NAMES):\n",
        "    model_info['test_performance']['per_class'][cls] = {\n",
        "        'precision': float(precision[i]),\n",
        "        'recall': float(recall[i]),\n",
        "        'f1_score': float(f1[i]),\n",
        "        'support': int(support[i])\n",
        "    }\n",
        "\n",
        "# Save\n",
        "model_info_path = os.path.join(MODEL_DIR, 'model_info.json')\n",
        "with open(model_info_path, 'w') as f:\n",
        "    json.dump(model_info, f, indent=2)\n",
        "\n",
        "print(f\"Model information saved to: {model_info_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List saved files\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"SAVED FILES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for f in sorted(os.listdir(MODEL_DIR)):\n",
        "    file_path = os.path.join(MODEL_DIR, f)\n",
        "    size_kb = os.path.getsize(file_path) / 1024\n",
        "    if size_kb > 1024:\n",
        "        print(f\"  {f} ({size_kb/1024:.1f} MB)\")\n",
        "    else:\n",
        "        print(f\"  {f} ({size_kb:.1f} KB)\")\n",
        "\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 20. Final Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 85)\n",
        "print(\"                LEAF DIEBACK DETECTION MODEL v6 - FINAL SUMMARY\")\n",
        "print(\"=\" * 85)\n",
        "\n",
        "print(\"\\nMODEL INFORMATION:\")\n",
        "print(\"-\" * 65)\n",
        "print(f\"  Name:              Leaf Dieback Detection Model v6\")\n",
        "print(f\"  Architecture:      MobileNetV2 (Transfer Learning)\")\n",
        "print(f\"  Loss Function:     Focal Loss (gamma=2.0)\")\n",
        "print(f\"  Input Size:        {IMG_SIZE}x{IMG_SIZE}x3\")\n",
        "print(f\"  Classes:           {CLASS_NAMES}\")\n",
        "\n",
        "print(\"\\nTRAINING SUMMARY:\")\n",
        "print(\"-\" * 65)\n",
        "print(f\"  Phase 1 (Frozen):     {len(history_phase1.history['accuracy'])} epochs\")\n",
        "print(f\"  Phase 2 (Fine-tune):  {len(history_phase2.history['accuracy'])} epochs\")\n",
        "print(f\"  Total Training Time:  {total_time:.1f} minutes\")\n",
        "\n",
        "print(\"\\nTEST PERFORMANCE:\")\n",
        "print(\"-\" * 65)\n",
        "print(f\"  Test Accuracy:        {test_accuracy*100:.2f}%\")\n",
        "print(f\"  Macro Precision:      {macro_precision*100:.2f}%\")\n",
        "print(f\"  Macro Recall:         {macro_recall*100:.2f}%\")\n",
        "print(f\"  Macro F1-Score:       {macro_f1*100:.2f}%\")\n",
        "\n",
        "print(\"\\nCLASS-WISE PERFORMANCE:\")\n",
        "print(\"-\" * 65)\n",
        "for i, cls in enumerate(CLASS_NAMES):\n",
        "    print(f\"  {cls:<18} P={precision[i]*100:5.2f}%  R={recall[i]*100:5.2f}%  F1={f1[i]*100:5.2f}%\")\n",
        "\n",
        "print(\"\\nQUALITY CHECKS (Madam's Requirements):\")\n",
        "print(\"-\" * 65)\n",
        "print(f\"  Overfitting (Train-Val gap):      {acc_gap*100:.2f}%  {'Pass' if acc_gap < 0.10 else 'Check'}\")\n",
        "print(f\"  Accuracy-F1 alignment:            {acc_f1_diff*100:.2f}%  {'Pass' if acc_f1_diff < 0.05 else 'Check'}\")\n",
        "print(f\"  Cross-class F1 range:             {(max(f1)-min(f1))*100:.2f}%  {'Pass' if (max(f1)-min(f1)) < 0.15 else 'Check'}\")\n",
        "\n",
        "for i, cls in enumerate(CLASS_NAMES):\n",
        "    p, r, f = precision[i], recall[i], f1[i]\n",
        "    max_diff = max(abs(p-r), abs(p-f), abs(r-f))\n",
        "    status = 'Pass' if max_diff < 0.10 else 'Check'\n",
        "    print(f\"  {cls} P/R/F1 balance:  {max_diff*100:.2f}%  {status}\")\n",
        "\n",
        "print(\"\\nOUTPUT FILES:\")\n",
        "print(\"-\" * 65)\n",
        "print(f\"  Model:       {MODEL_DIR}/best_model.keras\")\n",
        "print(f\"  Info:        {MODEL_DIR}/model_info.json\")\n",
        "print(f\"  Charts:      {MODEL_DIR}/*.png\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 85)\n",
        "print(\"                         TRAINING COMPLETE!\")\n",
        "print(\"=\" * 85)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
