{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "# Coconut Mite Detection Model - Proper Training\n",
        "\n",
        "**Model:** MobileNetV2 (Transfer Learning)  \n",
        "**Dataset:** Coconut Mite vs Healthy Leaves  \n",
        "\n",
        "## Dataset Structure (Pre-organized by User):\n",
        "- **Train:** 8,975 images (augmented)\n",
        "- **Validation:** 188 images (originals only)\n",
        "- **Test:** 189 images (originals only)\n",
        "\n",
        "## Madam's Requirements:\n",
        "1. P/R/F1 close for each class\n",
        "2. Similar F1 across classes\n",
        "3. Accuracy close to F1\n",
        "4. Step-by-step notebook with outputs\n",
        "5. No hardcoded values\n",
        "6. Charts included"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-1",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "import json\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
        "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
        "    print(f\"GPU Device: {tf.config.list_physical_devices('GPU')}\")\n",
        "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-3",
      "metadata": {},
      "source": [
        "## 2. Configuration\n",
        "\n",
        "All hyperparameters defined here - NO hardcoded values in training code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paths - Using EXISTING folder structure\n",
        "BASE_DIR = Path(r\"D:\\SLIIT\\Reaserch Project\\CoconutHealthMonitor\\Research\\ml\")\n",
        "DATA_DIR = BASE_DIR / 'data' / 'raw' / 'pest'\n",
        "COMBINED_DIR = BASE_DIR / 'data' / 'raw' / 'pest_combined'  # Will create TF-compatible structure\n",
        "MODEL_DIR = BASE_DIR / 'models' / 'coconut_mite_v6'\n",
        "\n",
        "# Create model directory\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Hyperparameters\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE = 1e-4\n",
        "DROPOUT_RATE = 0.5\n",
        "L2_REG = 0.01\n",
        "\n",
        "# Class names\n",
        "CLASS_NAMES = ['coconut_mite', 'healthy']\n",
        "\n",
        "print(\"Configuration:\")\n",
        "print(f\"  Data Directory: {DATA_DIR}\")\n",
        "print(f\"  Model Directory: {MODEL_DIR}\")\n",
        "print(f\"  Image Size: {IMG_SIZE}\")\n",
        "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"  Epochs: {EPOCHS}\")\n",
        "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"  Dropout Rate: {DROPOUT_RATE}\")\n",
        "print(f\"  L2 Regularization: {L2_REG}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-5",
      "metadata": {},
      "source": [
        "## 3. Analyze Existing Dataset Structure\n",
        "\n",
        "Count images in each pre-organized folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-6",
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_images(directory):\n",
        "    \"\"\"Count image files in a directory.\"\"\"\n",
        "    if not directory.exists():\n",
        "        return 0\n",
        "    count = 0\n",
        "    for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
        "        count += len(list(directory.glob(ext)))\n",
        "    return count\n",
        "\n",
        "print(\"Analyzing Existing Dataset Structure...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Define folder mappings (handling lowercase 'test' in healthy)\n",
        "folder_mapping = {\n",
        "    'coconut_mite': {'train': 'Train', 'validation': 'Validation', 'test': 'Test'},\n",
        "    'healthy': {'train': 'Train', 'validation': 'Validation', 'test': 'test'}  # lowercase!\n",
        "}\n",
        "\n",
        "dataset_counts = {'train': {}, 'validation': {}, 'test': {}}\n",
        "\n",
        "for cls in CLASS_NAMES:\n",
        "    print(f\"\\nClass: {cls}\")\n",
        "    for split in ['train', 'validation', 'test']:\n",
        "        folder_name = folder_mapping[cls][split]\n",
        "        folder_path = DATA_DIR / cls / folder_name\n",
        "        count = count_images(folder_path)\n",
        "        dataset_counts[split][cls] = count\n",
        "        print(f\"  {split.capitalize():12}: {count:,} images ({folder_path})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DATASET SUMMARY:\")\n",
        "print(\"=\"*60)\n",
        "for split in ['train', 'validation', 'test']:\n",
        "    total = sum(dataset_counts[split].values())\n",
        "    print(f\"{split.capitalize():12}: {dataset_counts[split]} = {total:,} images\")\n",
        "\n",
        "total_all = sum(sum(dataset_counts[s].values()) for s in dataset_counts)\n",
        "print(f\"\\nTOTAL: {total_all:,} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-7",
      "metadata": {},
      "source": [
        "## 4. Create TensorFlow-Compatible Directory Structure\n",
        "\n",
        "TensorFlow's `image_dataset_from_directory` expects:\n",
        "```\n",
        "split/\n",
        "  class1/\n",
        "  class2/\n",
        "```\n",
        "\n",
        "We'll create symbolic links to avoid duplicating data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def create_combined_structure(data_dir, combined_dir, class_names, folder_mapping):\n",
        "    \"\"\"\n",
        "    Create TensorFlow-compatible directory structure using file copying.\n",
        "    Structure: combined_dir/split/class/images\n",
        "    \"\"\"\n",
        "    # Clean existing\n",
        "    if combined_dir.exists():\n",
        "        shutil.rmtree(combined_dir)\n",
        "    \n",
        "    print(\"Creating TensorFlow-compatible directory structure...\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    for split in ['train', 'validation', 'test']:\n",
        "        for cls in class_names:\n",
        "            # Source folder\n",
        "            src_folder = folder_mapping[cls][split]\n",
        "            src_path = data_dir / cls / src_folder\n",
        "            \n",
        "            # Destination folder\n",
        "            dst_path = combined_dir / split / cls\n",
        "            dst_path.mkdir(parents=True, exist_ok=True)\n",
        "            \n",
        "            # Copy files (using hard links to save space on Windows)\n",
        "            if src_path.exists():\n",
        "                file_count = 0\n",
        "                for img_file in src_path.iterdir():\n",
        "                    if img_file.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
        "                        dst_file = dst_path / img_file.name\n",
        "                        try:\n",
        "                            # Try hard link first (saves space)\n",
        "                            os.link(str(img_file), str(dst_file))\n",
        "                        except OSError:\n",
        "                            # Fall back to copy if hard link fails\n",
        "                            shutil.copy2(img_file, dst_file)\n",
        "                        file_count += 1\n",
        "                print(f\"  {split}/{cls}: {file_count} files linked\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"Combined directory created: {combined_dir}\")\n",
        "    return combined_dir\n",
        "\n",
        "# Create the structure\n",
        "combined_dir = create_combined_structure(DATA_DIR, COMBINED_DIR, CLASS_NAMES, folder_mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-9",
      "metadata": {},
      "source": [
        "## 5. Visualize Dataset Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-10",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize distribution\n",
        "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
        "colors = ['#e74c3c', '#2ecc71']  # Red for mite, green for healthy\n",
        "\n",
        "for ax, split in zip(axes, ['train', 'validation', 'test']):\n",
        "    vals = [dataset_counts[split][c] for c in CLASS_NAMES]\n",
        "    total = sum(vals)\n",
        "    bars = ax.bar(CLASS_NAMES, vals, color=colors, edgecolor='black', linewidth=1.5)\n",
        "    \n",
        "    title_suffix = \"(augmented)\" if split == 'train' else \"(originals)\"\n",
        "    ax.set_title(f'{split.capitalize()} Set\\n{total:,} images {title_suffix}', \n",
        "                 fontsize=11, fontweight='bold')\n",
        "    ax.set_ylabel('Number of Images')\n",
        "    ax.set_ylim([0, max(vals) * 1.2 if max(vals) > 0 else 10])\n",
        "    \n",
        "    for bar, v in zip(bars, vals):\n",
        "        ax.text(bar.get_x() + bar.get_width()/2, v + max(vals)*0.02, \n",
        "                f'{v:,}', ha='center', fontweight='bold', fontsize=11)\n",
        "\n",
        "plt.suptitle('Dataset Distribution (Pre-organized - No Data Leakage)', fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig(MODEL_DIR / 'dataset_distribution.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Chart saved: {MODEL_DIR / 'dataset_distribution.png'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-11",
      "metadata": {},
      "source": [
        "## 6. Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-12",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load datasets from combined structure\n",
        "print(\"Loading datasets...\")\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    str(COMBINED_DIR / 'train'),\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    str(COMBINED_DIR / 'validation'),\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    str(COMBINED_DIR / 'test'),\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "detected_classes = train_ds.class_names\n",
        "print(f\"\\nDetected Classes: {detected_classes}\")\n",
        "print(f\"Training batches: {len(train_ds)}\")\n",
        "print(f\"Validation batches: {len(val_ds)}\")\n",
        "print(f\"Test batches: {len(test_ds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-13",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show sample images\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "fig.suptitle('Sample Images from Training Set', fontsize=14, fontweight='bold')\n",
        "\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if i < len(images):\n",
        "            ax.imshow(images[i].numpy().astype('uint8'))\n",
        "            cls_name = detected_classes[labels[i]]\n",
        "            color = 'red' if 'mite' in cls_name else 'green'\n",
        "            ax.set_title(cls_name, fontsize=10, color=color)\n",
        "            ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(MODEL_DIR / 'sample_images.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-14",
      "metadata": {},
      "source": [
        "## 7. Data Preprocessing\n",
        "\n",
        "- **Training:** On-the-fly augmentation + Normalization\n",
        "- **Validation/Test:** Normalization ONLY (no augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-15",
      "metadata": {},
      "outputs": [],
      "source": [
        "# On-the-fly data augmentation (ONLY for training)\n",
        "# Note: Training data already has augmented images, but we add light augmentation\n",
        "# for additional variation during training\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip('horizontal'),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "], name='data_augmentation')\n",
        "\n",
        "# Normalization (MobileNetV2 expects [-1, 1])\n",
        "normalization = tf.keras.layers.Rescaling(1./127.5, offset=-1, name='normalization')\n",
        "\n",
        "# Preprocessing functions\n",
        "def preprocess_train(image, label):\n",
        "    \"\"\"Training: light augmentation + normalization\"\"\"\n",
        "    image = data_augmentation(image, training=True)\n",
        "    image = normalization(image)\n",
        "    return image, label\n",
        "\n",
        "def preprocess_val(image, label):\n",
        "    \"\"\"Validation/Test: normalization only\"\"\"\n",
        "    image = normalization(image)\n",
        "    return image, label\n",
        "\n",
        "# Apply preprocessing\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds_prep = train_ds.map(preprocess_train, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
        "val_ds_prep = val_ds.map(preprocess_val, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
        "test_ds_prep = test_ds.map(preprocess_val, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
        "\n",
        "print(\"Preprocessing Applied:\")\n",
        "print(\"  Training:   Light Augmentation + Normalization [-1, 1]\")\n",
        "print(\"  Validation: Normalization [-1, 1] only\")\n",
        "print(\"  Test:       Normalization [-1, 1] only\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-16",
      "metadata": {},
      "source": [
        "## 8. Build Model\n",
        "\n",
        "MobileNetV2 with strong regularization to prevent overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-17",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_model(img_size, dropout_rate, l2_reg):\n",
        "    \"\"\"\n",
        "    Build MobileNetV2 model with strong regularization.\n",
        "    \"\"\"\n",
        "    # Load pre-trained MobileNetV2\n",
        "    base_model = MobileNetV2(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(img_size[0], img_size[1], 3)\n",
        "    )\n",
        "    \n",
        "    # Freeze base model initially\n",
        "    base_model.trainable = False\n",
        "    \n",
        "    # Build model with regularization\n",
        "    inputs = tf.keras.Input(shape=(img_size[0], img_size[1], 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(128, activation='relu', kernel_regularizer=l2(l2_reg))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Dense(64, activation='relu', kernel_regularizer=l2(l2_reg))(x)\n",
        "    x = Dropout(dropout_rate / 2)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "    \n",
        "    return model, base_model\n",
        "\n",
        "# Build model\n",
        "model, base_model = build_model(IMG_SIZE, DROPOUT_RATE, L2_REG)\n",
        "\n",
        "print(\"Model Architecture:\")\n",
        "print(f\"  Base Model: MobileNetV2 (ImageNet weights)\")\n",
        "print(f\"  Base Model Layers: {len(base_model.layers)}\")\n",
        "print(f\"  Total Parameters: {model.count_params():,}\")\n",
        "trainable = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
        "print(f\"  Trainable Parameters: {trainable:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-18",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-19",
      "metadata": {},
      "source": [
        "## 9. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-20",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        str(MODEL_DIR / 'best_model.keras'),\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"Training Configuration:\")\n",
        "print(f\"  Optimizer: Adam\")\n",
        "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"  Loss: Binary Crossentropy\")\n",
        "print(f\"  Max Epochs: {EPOCHS}\")\n",
        "print(f\"  Early Stopping Patience: 10\")\n",
        "print(f\"  LR Reduction Patience: 5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-21",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train model\n",
        "print(\"\\nStarting Training...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds_prep,\n",
        "    validation_data=val_ds_prep,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Training Complete!\")\n",
        "print(f\"Epochs trained: {len(history.history['accuracy'])}\")\n",
        "print(f\"Best Validation Accuracy: {max(history.history['val_accuracy'])*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-22",
      "metadata": {},
      "source": [
        "## 10. Training History Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-23",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save training history\n",
        "history_dict = {\n",
        "    'accuracy': [float(x) for x in history.history['accuracy']],\n",
        "    'val_accuracy': [float(x) for x in history.history['val_accuracy']],\n",
        "    'loss': [float(x) for x in history.history['loss']],\n",
        "    'val_loss': [float(x) for x in history.history['val_loss']],\n",
        "}\n",
        "\n",
        "with open(MODEL_DIR / 'training_history.json', 'w') as f:\n",
        "    json.dump(history_dict, f, indent=2)\n",
        "\n",
        "print(f\"Training history saved: {MODEL_DIR / 'training_history.json'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-24",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "epochs_range = range(1, len(history_dict['accuracy']) + 1)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Accuracy\n",
        "axes[0].plot(epochs_range, history_dict['accuracy'], 'b-o', label='Training', markersize=4, linewidth=2)\n",
        "axes[0].plot(epochs_range, history_dict['val_accuracy'], 'r-s', label='Validation', markersize=4, linewidth=2)\n",
        "\n",
        "best_epoch = history_dict['val_accuracy'].index(max(history_dict['val_accuracy'])) + 1\n",
        "best_val_acc = max(history_dict['val_accuracy'])\n",
        "axes[0].scatter([best_epoch], [best_val_acc], color='green', s=200, zorder=5, marker='*',\n",
        "                label=f'Best: {best_val_acc*100:.2f}%')\n",
        "\n",
        "axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
        "axes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
        "axes[0].legend(loc='lower right')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Loss\n",
        "axes[1].plot(epochs_range, history_dict['loss'], 'b-o', label='Training', markersize=4, linewidth=2)\n",
        "axes[1].plot(epochs_range, history_dict['val_loss'], 'r-s', label='Validation', markersize=4, linewidth=2)\n",
        "axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1].set_ylabel('Loss', fontsize=12)\n",
        "axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
        "axes[1].legend(loc='upper right')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Calculate gap\n",
        "final_train_acc = history_dict['accuracy'][-1]\n",
        "final_val_acc = history_dict['val_accuracy'][-1]\n",
        "gap = abs(final_train_acc - final_val_acc)\n",
        "\n",
        "plt.suptitle(f'Training History (Train-Val Gap: {gap*100:.2f}%)', fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig(MODEL_DIR / 'training_history.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nFinal Training Accuracy: {final_train_acc*100:.2f}%\")\n",
        "print(f\"Final Validation Accuracy: {final_val_acc*100:.2f}%\")\n",
        "print(f\"Train-Val Gap: {gap*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-25",
      "metadata": {},
      "source": [
        "## 11. Test Set Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-26",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model\n",
        "best_model = tf.keras.models.load_model(str(MODEL_DIR / 'best_model.keras'))\n",
        "print(f\"Loaded best model: {MODEL_DIR / 'best_model.keras'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-27",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions on test set\n",
        "y_true = []\n",
        "y_pred_probs = []\n",
        "\n",
        "print(\"Running predictions on test set...\")\n",
        "for images, labels in test_ds_prep:\n",
        "    preds = best_model.predict(images, verbose=0)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred_probs.extend(preds.flatten())\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred_probs = np.array(y_pred_probs)\n",
        "\n",
        "print(f\"Test samples: {len(y_true)}\")\n",
        "print(f\"Class distribution: {dict(zip(*np.unique(y_true, return_counts=True)))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-28",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find optimal threshold for balanced Precision/Recall\n",
        "print(\"Finding optimal threshold for balanced Precision/Recall...\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "thresholds = np.arange(0.1, 0.9, 0.05)\n",
        "results = []\n",
        "\n",
        "for thresh in thresholds:\n",
        "    y_pred_temp = (y_pred_probs > thresh).astype(int)\n",
        "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred_temp, average=None, zero_division=0)\n",
        "    \n",
        "    # Calculate gaps\n",
        "    max_pr_gap = max(abs(p[0] - r[0]), abs(p[1] - r[1])) if len(p) > 1 else abs(p[0] - r[0])\n",
        "    f1_diff = abs(f1[0] - f1[1]) if len(f1) > 1 else 0\n",
        "    combined = max_pr_gap + f1_diff\n",
        "    acc = np.mean(y_true == y_pred_temp)\n",
        "    \n",
        "    results.append({\n",
        "        'threshold': thresh,\n",
        "        'max_pr_gap': max_pr_gap,\n",
        "        'f1_diff': f1_diff,\n",
        "        'combined': combined,\n",
        "        'accuracy': acc,\n",
        "        'macro_f1': np.mean(f1)\n",
        "    })\n",
        "    \n",
        "    print(f\"Thresh {thresh:.2f}: P-R Gap={max_pr_gap:.3f}, F1 Diff={f1_diff:.3f}, Acc={acc*100:.1f}%, F1={np.mean(f1)*100:.1f}%\")\n",
        "\n",
        "# Find best threshold (minimize combined gap)\n",
        "best_result = min(results, key=lambda x: x['combined'])\n",
        "OPTIMAL_THRESHOLD = best_result['threshold']\n",
        "\n",
        "print(\"-\"*60)\n",
        "print(f\"Optimal Threshold: {OPTIMAL_THRESHOLD:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-29",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply optimal threshold\n",
        "y_pred = (y_pred_probs > OPTIMAL_THRESHOLD).astype(int)\n",
        "\n",
        "# Calculate final metrics\n",
        "accuracy = np.mean(y_true == y_pred)\n",
        "p, r, f1, support = precision_recall_fscore_support(y_true, y_pred, average=None, zero_division=0)\n",
        "macro_f1 = np.mean(f1)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(\"=\"*60)\n",
        "print(classification_report(y_true, y_pred, target_names=detected_classes, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-30",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Counts\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
        "            xticklabels=detected_classes, yticklabels=detected_classes, annot_kws={'size': 20})\n",
        "axes[0].set_title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Predicted')\n",
        "axes[0].set_ylabel('Actual')\n",
        "\n",
        "# Normalized\n",
        "cm_norm = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 1e-10)\n",
        "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Blues', ax=axes[1],\n",
        "            xticklabels=detected_classes, yticklabels=detected_classes, annot_kws={'size': 16})\n",
        "axes[1].set_title('Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Predicted')\n",
        "axes[1].set_ylabel('Actual')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(MODEL_DIR / 'confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-31",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Performance Metrics Visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Overall metrics\n",
        "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "metrics_values = [accuracy, np.mean(p), np.mean(r), macro_f1]\n",
        "colors_metrics = ['#3498db', '#2ecc71', '#f39c12', '#e74c3c']\n",
        "\n",
        "bars = axes[0].bar(metrics_names, metrics_values, color=colors_metrics, edgecolor='black')\n",
        "axes[0].set_ylim([0, 1.1])\n",
        "axes[0].set_title('Overall Model Performance', fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylabel('Score')\n",
        "for bar, val in zip(bars, metrics_values):\n",
        "    axes[0].text(bar.get_x() + bar.get_width()/2, val + 0.02, f'{val:.2%}', ha='center', fontweight='bold')\n",
        "\n",
        "# Per-class metrics\n",
        "x = np.arange(len(detected_classes))\n",
        "width = 0.25\n",
        "axes[1].bar(x - width, p, width, label='Precision', color='#3498db', edgecolor='black')\n",
        "axes[1].bar(x, r, width, label='Recall', color='#2ecc71', edgecolor='black')\n",
        "axes[1].bar(x + width, f1, width, label='F1-Score', color='#e74c3c', edgecolor='black')\n",
        "axes[1].set_ylim([0, 1.1])\n",
        "axes[1].set_title('Per-Class Performance', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xticks(x)\n",
        "axes[1].set_xticklabels(detected_classes)\n",
        "axes[1].legend()\n",
        "axes[1].set_ylabel('Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(MODEL_DIR / 'performance_metrics.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-32",
      "metadata": {},
      "source": [
        "## 12. Madam's Requirements Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-33",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"MADAM'S REQUIREMENTS VALIDATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "all_pass = True\n",
        "TOLERANCE = 0.10  # 10% tolerance\n",
        "\n",
        "# Requirement 1: P/R/F1 balanced per class\n",
        "print(\"\\n[1] P/R/F1 should be close for EACH class (gap < 10%)\")\n",
        "print(\"-\"*60)\n",
        "for i, cls in enumerate(detected_classes):\n",
        "    pr_gap = abs(p[i] - r[i])\n",
        "    status = \"PASS\" if pr_gap < TOLERANCE else \"FAIL\"\n",
        "    if pr_gap >= TOLERANCE:\n",
        "        all_pass = False\n",
        "    print(f\"  {cls}:\")\n",
        "    print(f\"    Precision: {p[i]:.4f}\")\n",
        "    print(f\"    Recall:    {r[i]:.4f}\")\n",
        "    print(f\"    F1-Score:  {f1[i]:.4f}\")\n",
        "    print(f\"    P-R Gap:   {pr_gap:.4f} [{status}]\")\n",
        "\n",
        "# Requirement 2: F1 similar across classes\n",
        "print(\"\\n[2] F1-Scores should be similar across classes (diff < 10%)\")\n",
        "print(\"-\"*60)\n",
        "f1_diff = abs(f1[0] - f1[1]) if len(f1) > 1 else 0\n",
        "status = \"PASS\" if f1_diff < TOLERANCE else \"FAIL\"\n",
        "if f1_diff >= TOLERANCE:\n",
        "    all_pass = False\n",
        "for i, cls in enumerate(detected_classes):\n",
        "    print(f\"  {cls} F1: {f1[i]:.4f}\")\n",
        "print(f\"  F1 Difference: {f1_diff:.4f} [{status}]\")\n",
        "\n",
        "# Requirement 3: Accuracy close to F1\n",
        "print(\"\\n[3] Accuracy should be close to F1-Score (diff < 10%)\")\n",
        "print(\"-\"*60)\n",
        "acc_f1_diff = abs(accuracy - macro_f1)\n",
        "status = \"PASS\" if acc_f1_diff < TOLERANCE else \"FAIL\"\n",
        "if acc_f1_diff >= TOLERANCE:\n",
        "    all_pass = False\n",
        "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"  Macro F1:  {macro_f1:.4f}\")\n",
        "print(f\"  Difference: {acc_f1_diff:.4f} [{status}]\")\n",
        "\n",
        "# Requirement 4: No severe overfitting\n",
        "print(\"\\n[4] Train-Val gap should be small (gap < 15%)\")\n",
        "print(\"-\"*60)\n",
        "train_val_gap = abs(final_train_acc - final_val_acc)\n",
        "status = \"PASS\" if train_val_gap < 0.15 else \"FAIL\"\n",
        "if train_val_gap >= 0.15:\n",
        "    all_pass = False\n",
        "print(f\"  Training Accuracy:   {final_train_acc:.4f}\")\n",
        "print(f\"  Validation Accuracy: {final_val_acc:.4f}\")\n",
        "print(f\"  Gap: {train_val_gap:.4f} [{status}]\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "if all_pass:\n",
        "    print(\"ALL REQUIREMENTS PASSED!\")\n",
        "else:\n",
        "    print(\"SOME REQUIREMENTS NEED ATTENTION\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-34",
      "metadata": {},
      "source": [
        "## 13. Save Model Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-35",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model info\n",
        "model_info = {\n",
        "    'model_name': 'Coconut Mite Detection Model v6',\n",
        "    'base_model': 'MobileNetV2',\n",
        "    'input_size': list(IMG_SIZE) + [3],\n",
        "    'classes': detected_classes,\n",
        "    'threshold': float(OPTIMAL_THRESHOLD),\n",
        "    'hyperparameters': {\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'dropout_rate': DROPOUT_RATE,\n",
        "        'l2_regularization': L2_REG,\n",
        "        'epochs_trained': len(history_dict['accuracy'])\n",
        "    },\n",
        "    'dataset': {\n",
        "        'train': sum(dataset_counts['train'].values()),\n",
        "        'validation': sum(dataset_counts['validation'].values()),\n",
        "        'test': sum(dataset_counts['test'].values()),\n",
        "        'per_class': dataset_counts\n",
        "    },\n",
        "    'training_results': {\n",
        "        'final_train_accuracy': float(final_train_acc),\n",
        "        'final_val_accuracy': float(final_val_acc),\n",
        "        'best_val_accuracy': float(best_val_acc),\n",
        "        'train_val_gap': float(train_val_gap)\n",
        "    },\n",
        "    'test_results': {\n",
        "        'accuracy': float(accuracy),\n",
        "        'per_class': {},\n",
        "        'macro_f1': float(macro_f1)\n",
        "    },\n",
        "    'requirements_validation': {\n",
        "        'all_passed': all_pass\n",
        "    },\n",
        "    'timestamp': datetime.now().isoformat()\n",
        "}\n",
        "\n",
        "# Add per-class metrics\n",
        "for i, cls in enumerate(detected_classes):\n",
        "    model_info['test_results']['per_class'][cls] = {\n",
        "        'precision': float(p[i]),\n",
        "        'recall': float(r[i]),\n",
        "        'f1': float(f1[i]),\n",
        "        'support': int(support[i])\n",
        "    }\n",
        "\n",
        "with open(MODEL_DIR / 'model_info.json', 'w') as f:\n",
        "    json.dump(model_info, f, indent=2)\n",
        "\n",
        "print(f\"Model info saved: {MODEL_DIR / 'model_info.json'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-36",
      "metadata": {},
      "source": [
        "## 14. Final Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-37",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"TRAINING SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n--- Model ---\")\n",
        "print(f\"  Architecture: MobileNetV2 (Transfer Learning)\")\n",
        "print(f\"  Input Size: {IMG_SIZE[0]}x{IMG_SIZE[1]}x3\")\n",
        "print(f\"  Dropout: {DROPOUT_RATE}\")\n",
        "print(f\"  L2 Regularization: {L2_REG}\")\n",
        "\n",
        "print(f\"\\n--- Dataset ---\")\n",
        "print(f\"  Training: {sum(dataset_counts['train'].values()):,} images (augmented)\")\n",
        "print(f\"  Validation: {sum(dataset_counts['validation'].values()):,} images (originals)\")\n",
        "print(f\"  Test: {sum(dataset_counts['test'].values()):,} images (originals)\")\n",
        "\n",
        "print(f\"\\n--- Training ---\")\n",
        "print(f\"  Epochs: {len(history_dict['accuracy'])}\")\n",
        "print(f\"  Final Train Accuracy: {final_train_acc*100:.2f}%\")\n",
        "print(f\"  Final Val Accuracy: {final_val_acc*100:.2f}%\")\n",
        "print(f\"  Best Val Accuracy: {best_val_acc*100:.2f}%\")\n",
        "print(f\"  Train-Val Gap: {train_val_gap*100:.2f}%\")\n",
        "\n",
        "print(f\"\\n--- Test Results ---\")\n",
        "print(f\"  Threshold: {OPTIMAL_THRESHOLD:.2f}\")\n",
        "print(f\"  Test Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"  Macro F1-Score: {macro_f1*100:.2f}%\")\n",
        "\n",
        "print(f\"\\n--- Per-Class Results ---\")\n",
        "for i, cls in enumerate(detected_classes):\n",
        "    print(f\"  {cls}:\")\n",
        "    print(f\"    Precision: {p[i]*100:.2f}%\")\n",
        "    print(f\"    Recall: {r[i]*100:.2f}%\")\n",
        "    print(f\"    F1-Score: {f1[i]*100:.2f}%\")\n",
        "\n",
        "print(f\"\\n--- Files Saved ---\")\n",
        "print(f\"  {MODEL_DIR / 'best_model.keras'}\")\n",
        "print(f\"  {MODEL_DIR / 'model_info.json'}\")\n",
        "print(f\"  {MODEL_DIR / 'training_history.json'}\")\n",
        "print(f\"  {MODEL_DIR / 'training_history.png'}\")\n",
        "print(f\"  {MODEL_DIR / 'confusion_matrix.png'}\")\n",
        "print(f\"  {MODEL_DIR / 'performance_metrics.png'}\")\n",
        "print(f\"  {MODEL_DIR / 'dataset_distribution.png'}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "if all_pass:\n",
        "    print(\"ALL MADAM'S REQUIREMENTS: PASSED\")\n",
        "else:\n",
        "    print(\"SOME REQUIREMENTS NEED ATTENTION\")\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
